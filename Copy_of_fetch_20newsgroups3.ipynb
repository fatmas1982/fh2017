{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of fetch_20newsgroups.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fatmas1982/fh2017/blob/master/Copy_of_fetch_20newsgroups3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "me14sBCEuffI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "39c5d119-e2fe-4102-bb58-ce8787a93854"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot') \n",
        "import numpy as np\n",
        "import scipy.stats.stats as st\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "#from stemming.porter2 import stem\n",
        "from nltk import PorterStemmer\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from string import digits\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import csv\n",
        "\n",
        "import re\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "!pip install gensim\n",
        "import  gensim.models as md\n",
        "from gensim.models.phrases import Phrases, Phraser\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.5.7)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.7.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.48.0)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.11.0,>=1.10.13 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.10.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.13->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.13->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GvYYCnMyytqW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aikWxQjx05u4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2327
        },
        "outputId": "6d4b4ddf-3b60-4d86-b946-b00696c7afc2"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18298 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.1_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.1) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.1) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmp60jw87yg/pubring.gpg' created\n",
            "gpg: /tmp/tmp60jw87yg/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19706 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fzwzSluP1BRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SR-ozY_l1OaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4d6ed9f3-00b4-418b-db09-48bd968de09c"
      },
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/notebook#fileId=1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q&scrollTo=c99EvWo1s9-x\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iCxyYidh13d-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7e921edf-c518-47b6-f46b-ee0cd51ccc4a"
      },
      "cell_type": "code",
      "source": [
        "!ls \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab   file.txt   nytimes_news_articles.txt\tstopwords.txt\r\n",
            "drive_PH  nltk_data  scikit_learn_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7VU7uSU82Uwy",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "f87fc1f3-7e5e-474e-f8ed-9dd322f920dc"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a285f64-e6ef-4266-b8cf-b4c324760dd9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3a285f64-e6ef-4266-b8cf-b4c324760dd9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving nytimes_news_articles.txt to nytimes_news_articles.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GNP8Uhv525hA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive_PH\n",
        "!google-drive-ocamlfuse drive_PH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TRIVr4TKuzbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_database='./drive_PH/Colab Notebooks/' \n",
        "\n",
        "pragraph_index='pragraph_index_20.csv'\n",
        "Sentences='Sentences_20.csv'\n",
        "Sentences_not_stops='Sentences_not_stops_20.csv'\n",
        "lesk='lesk_20.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FzyPK8SaloNo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0IcKS15EmGUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "8d484c10-10cf-4fab-ee3d-16b8eb3859c6"
      },
      "cell_type": "code",
      "source": [
        "documents[0]\n",
        "dataset.filenames"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.mideast/76141',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/53281',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.mideast/76350',\n",
              "       ...,\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.baseball/105105',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51575',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.baseball/104908'],\n",
              "      dtype='<U89')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "KwUghKOWPuty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOs-pWWeuaMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write Excell sheet\n",
        "'''\n",
        "def save_file_to_database(data_rows,path_database,file_databbase,header_list):#header_list=['index','text']\n",
        "    outfile = open(path_database+file_databbase,'w')\n",
        "    writer=csv.writer(outfile)\n",
        "    #header_list=['uuid','paragraph','doc_id']\n",
        "    i=0\n",
        "    for line in data_rows:\n",
        "        row=[i,line]#,'paragraph no.'+str(i)]\n",
        "        if i==0:\n",
        "            \n",
        "            writer.writerow(header_list)\n",
        "            writer.writerow(row)\n",
        "        else:\n",
        "            #print('ff')\n",
        "            writer.writerow(row)\n",
        "        i+= 1\n",
        "        #outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFmp8dmuP0hs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_file_to_database(documents,path_database,pragraph_index,header_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVChg9cLwyD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_cvs_by_pands(path_database,file_databbase,index_col, header):\n",
        "    return pd.read_csv(path_database+file_databbase,index_col=index_col,header=header)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrjPdQNfwy3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pragraph_to_setnences(str):\n",
        "    return sent_tokenize(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVlUCEHeRxxC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def txt_pragraphs(str):\n",
        "    pragraphs = str.split(\"\\n\\n\")\n",
        "    return pragraphs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrY0paf2w7LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_text_from_database(path_database,file_databbase):\n",
        "    queue_paragraph=[]\n",
        "    #f = open(sys.argv[1], 'rt')\n",
        "    outfile = open(path_database+file_databbase,'rt')\n",
        "    try:\n",
        "                \n",
        "        reader=csv.reader(outfile)\n",
        "        for row in reader:\n",
        "            queue_paragraph.append(row)\n",
        "            #print (row)\n",
        "    finally:\n",
        "        print (\"row\")\n",
        "        outfile.close()\n",
        "        \n",
        "    return queue_paragraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEoC0O_-w7C2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stopwords_list():\n",
        "    stopwordsFile = open('./stopwords.txt')\n",
        "    stopwordsFile.seek(0)\n",
        "    stopwordsV1 = stopwordsFile.readlines()\n",
        "    stopwordsV2 = []\n",
        "    for sent in stopwordsV1:\n",
        "        sent.replace('\\n', '')\n",
        "        new_word = sent[0:len(sent) - 1]\n",
        "        stopwordsV2.append(new_word.lower())\n",
        "    return stopwordsV2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYP_EfTsw62c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_stop_words = ['the', 'that', 'to', 'as', 'there', 'has', 'and', 'or', 'is', 'not', 'a', 'of', 'but', 'in', 'by', 'on', 'are', 'it', 'if','what','where','how','when']\n",
        "new_stop_words2=['--','i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now','even','until','then','must']\n",
        "numbers=[1,2,3,4,5,6,7,8,9]\n",
        "stopwordsV2=stopwords_list()\n",
        "#stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "def remove_stopword_sentences(str):\n",
        "   \n",
        "            \n",
        "    list_word=[]\n",
        "    tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "    \n",
        "    words=tokenizer.tokenize(str)\n",
        "    for word in words:\n",
        "        new_word = word.encode('ascii', 'ignore').decode('utf-8')\n",
        "        if new_word != '':\n",
        "    \n",
        "            english_stops = set(stopwords.words('english'))\n",
        "           \n",
        "            list_word=[new_word for new_word in words if new_word.lower() not in english_stops\n",
        "                       and new_word.lower() not in new_stop_words \n",
        "                       and new_word.lower() not in new_stop_words2 \n",
        "                       and  not new_word.lower().isdigit() \n",
        "                       and new_word.lower() not in digits \n",
        "                       and new_word.lower() not in  numbers and word.lower() not in stopwordsV2\n",
        "                       and new_word.lower() not in string.punctuation]\n",
        "    \n",
        "  \n",
        "    \n",
        "    return list_word#(stem(setem_word for setem_word in  ([word for word in words if word not in english_stops and word not in new_stop_words])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wC8vNEEaw6hE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60eaf98e-d667-4033-c3f7-4e85c82afb08"
      },
      "cell_type": "code",
      "source": [
        "!ls nytimes_news_articles.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nytimes_news_articles.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "64fBKXlnBYIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def courps_to_CSV_docs():\n",
        "    #Reading the news articles file\n",
        "    nyTimesFile = open('./nytimes_news_articles.txt', encoding='latin-1')\n",
        "    nyTimesFile.seek(0)\n",
        "    nyTimesV1 = nyTimesFile.readlines()\n",
        "    nyTimesTemp = []\n",
        "    nyTimesURL = []\n",
        "\n",
        "    for i in range(0, len(nyTimesV1)-1):\n",
        "        if re.findall('URL', nyTimesV1[i]) == []:\n",
        "            sent = sent + nyTimesV1[i]\n",
        "            if (re.findall('URL', nyTimesV1[i+1]) != []) and (i+1 < len(nyTimesV1)):\n",
        "                nyTimesTemp.append(sent.strip())\n",
        "        else:\n",
        "            sent = ''\n",
        "            nyTimesURL.append(nyTimesV1[i])\n",
        "\n",
        "    for i in range(0, len(nyTimesTemp)):\n",
        "        nyTimesTemp[i] = nyTimesTemp[i]+'articleID'+str(i)\n",
        "    print(len(nyTimesTemp))\n",
        "    header_list=['index','text']\n",
        "    save_file_to_database(nyTimesTemp,path_database,pragraph_index,header_list)\n",
        "    '''for i in range(1):\n",
        "        print(i,\"============================================\")\n",
        "        print(\"============================================\")'''\n",
        "    #nytimes = preProcessor(nyTimesTemp)\n",
        "    print(\"============================================\")\n",
        "    #print(nytimes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36a6-R2FBcZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3f2afd55-9ad7-4f2e-d2a8-25b8841a9102"
      },
      "cell_type": "code",
      "source": [
        "#courps_to_CSV_docs()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "61\n",
            "============================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxfC-Owjmby8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "header_list=['index','text']\n",
        "#save_file_to_database(documents,'/',pragraph_index,header_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXOY0cobvZEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "de3e2b15-68cf-4e50-c6ea-469b7097028c"
      },
      "cell_type": "code",
      "source": [
        "paragraphs=read_cvs_by_pands(path_database,pragraph_index,None,0)\n",
        "paragraphs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Well i'm not sure about the story nad it did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Although I realize that principle is not one o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Well, I will have to change the scoring on my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>\\n \\nI read somewhere, I think in Morton Smit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>\\nOk.  I have a record that shows a IIsi with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>\\n\\n\\nSounds like wishful guessing.\\n\\n\\n\\n\\n'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Nobody is saying that you shouldn't be allowe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>\\n  I was wondering if anyone can shed any lig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>Archive-name: graphics/resources-list/part1\\nL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>I have a Roberto Clemente 1969 Topps baseball ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>\\n\\n\"Diet Evangelist\".  Good term.  Fits Atkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>Hi Damon,  No matter what system or explanatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>The title says it all.  I need to know the 44,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>\\nCan't we move the political bickering to a m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Exactly.\\n\\nBut I'll add another observation: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>\\nAnd of course, Mike Ramsey was (at one time)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>In Texas (Well, Corpus Christi anyway) if you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>\\n   I'm sorry, I thought we were discussing h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>\\n\\n\\n\\n\\tI'd like to see this info as well.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>Just a shot here, but ya never know:\\n\\nI once...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>\\nThere is a (likely) veto proof majority in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>\\n\\n\\n\\n\"Put not your trust in princes\" is the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>As I promised, I would give you the name of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>The concept of God as a teacher is indeed inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>\\nIt really doesn't strike me as very funny. I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>\\n\\nI don't know, but I'm as willing to specul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>GAME(S) OF 4/15\\n---------------\\nADIRONDACK 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>\\nYes!  Up the coast, over to Portland, then u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11284</th>\n",
              "      <td>11284</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11285</th>\n",
              "      <td>11285</td>\n",
              "      <td>\\nLike, there's a FAQ for this?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11286</th>\n",
              "      <td>11286</td>\n",
              "      <td>REQUEST FOR DISCUSSION\\n\\nThis is a request fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11287</th>\n",
              "      <td>11287</td>\n",
              "      <td>Pardon me if this is the wrong newsgroup.  I w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11288</th>\n",
              "      <td>11288</td>\n",
              "      <td>Hi there,\\n\\nis there anybody who know a polyg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11289</th>\n",
              "      <td>11289</td>\n",
              "      <td>Since someone brought up sports radio, howabou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11290</th>\n",
              "      <td>11290</td>\n",
              "      <td>\\n[...]\\n \\n      Well, chalk one up for driv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11291</th>\n",
              "      <td>11291</td>\n",
              "      <td>(please respond via email!)\\n\\nHas anybody act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11292</th>\n",
              "      <td>11292</td>\n",
              "      <td>Greetings!\\n   \\nI've had a bunch of problems ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11293</th>\n",
              "      <td>11293</td>\n",
              "      <td>\\n@===@                                       ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11294</th>\n",
              "      <td>11294</td>\n",
              "      <td>I had a catalog with membrane keypads, but I d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11295</th>\n",
              "      <td>11295</td>\n",
              "      <td>Oh boy, a little K-bike versus /2 scuffling? G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11296</th>\n",
              "      <td>11296</td>\n",
              "      <td>Hello to everybody,\\nI write here because I am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11297</th>\n",
              "      <td>11297</td>\n",
              "      <td>[reply to todamhyp@charles.unlv.edu (Brian M. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11298</th>\n",
              "      <td>11298</td>\n",
              "      <td>This is exactly what I have heard before.  If ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11299</th>\n",
              "      <td>11299</td>\n",
              "      <td>\\nWhats the difference between a V.32bis modem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11300</th>\n",
              "      <td>11300</td>\n",
              "      <td>[why do babies get diseases, etc.]\\n\\n Here's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11301</th>\n",
              "      <td>11301</td>\n",
              "      <td>I would like to know what people's opinions ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11302</th>\n",
              "      <td>11302</td>\n",
              "      <td>You might want to clarify the 11 game winning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11303</th>\n",
              "      <td>11303</td>\n",
              "      <td>\\nI totally agree with that sentiment.  But wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11304</th>\n",
              "      <td>11304</td>\n",
              "      <td>\\nI agree with what Darren has to say here, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11305</th>\n",
              "      <td>11305</td>\n",
              "      <td>Ok people, I really need to sell this sampler ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11306</th>\n",
              "      <td>11306</td>\n",
              "      <td>Hi,\\n\\n  I am trying to write an X-windows bas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11307</th>\n",
              "      <td>11307</td>\n",
              "      <td>I'd like to share my thoughts on this topic of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11308</th>\n",
              "      <td>11308</td>\n",
              "      <td>My sunroof leaks.  I've always thought those t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11309</th>\n",
              "      <td>11309</td>\n",
              "      <td>Danny Rubenstein, an Israeli journalist, will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11310</th>\n",
              "      <td>11310</td>\n",
              "      <td>\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11311</th>\n",
              "      <td>11311</td>\n",
              "      <td>\\nI agree.  Home runs off Clemens are always m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11312</th>\n",
              "      <td>11312</td>\n",
              "      <td>I used HP DeskJet with Orange Micros Grappler ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11313</th>\n",
              "      <td>11313</td>\n",
              "      <td>^^^^^^\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11314 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                               text\n",
              "0          0  Well i'm not sure about the story nad it did s...\n",
              "1          1  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
              "2          2  Although I realize that principle is not one o...\n",
              "3          3  Notwithstanding all the legitimate fuss about ...\n",
              "4          4  Well, I will have to change the scoring on my ...\n",
              "5          5   \\n \\nI read somewhere, I think in Morton Smit...\n",
              "6          6  \\nOk.  I have a record that shows a IIsi with ...\n",
              "7          7  \\n\\n\\nSounds like wishful guessing.\\n\\n\\n\\n\\n'...\n",
              "8          8   Nobody is saying that you shouldn't be allowe...\n",
              "9          9  \\n  I was wondering if anyone can shed any lig...\n",
              "10        10  Archive-name: graphics/resources-list/part1\\nL...\n",
              "11        11  I have a Roberto Clemente 1969 Topps baseball ...\n",
              "12        12  \\n\\n\"Diet Evangelist\".  Good term.  Fits Atkin...\n",
              "13        13  Hi Damon,  No matter what system or explanatio...\n",
              "14        14  The title says it all.  I need to know the 44,...\n",
              "15        15  \\nCan't we move the political bickering to a m...\n",
              "16        16  Exactly.\\n\\nBut I'll add another observation: ...\n",
              "17        17  \\nAnd of course, Mike Ramsey was (at one time)...\n",
              "18        18  In Texas (Well, Corpus Christi anyway) if you ...\n",
              "19        19  \\n   I'm sorry, I thought we were discussing h...\n",
              "20        20  \\n\\n\\n\\n\\tI'd like to see this info as well.  ...\n",
              "21        21  Just a shot here, but ya never know:\\n\\nI once...\n",
              "22        22  \\nThere is a (likely) veto proof majority in t...\n",
              "23        23  \\n\\n\\n\\n\"Put not your trust in princes\" is the...\n",
              "24        24  As I promised, I would give you the name of th...\n",
              "25        25  The concept of God as a teacher is indeed inte...\n",
              "26        26  \\nIt really doesn't strike me as very funny. I...\n",
              "27        27  \\n\\nI don't know, but I'm as willing to specul...\n",
              "28        28  GAME(S) OF 4/15\\n---------------\\nADIRONDACK 6...\n",
              "29        29  \\nYes!  Up the coast, over to Portland, then u...\n",
              "...      ...                                                ...\n",
              "11284  11284                                                ...\n",
              "11285  11285                  \\nLike, there's a FAQ for this?\\n\n",
              "11286  11286  REQUEST FOR DISCUSSION\\n\\nThis is a request fo...\n",
              "11287  11287  Pardon me if this is the wrong newsgroup.  I w...\n",
              "11288  11288  Hi there,\\n\\nis there anybody who know a polyg...\n",
              "11289  11289  Since someone brought up sports radio, howabou...\n",
              "11290  11290   \\n[...]\\n \\n      Well, chalk one up for driv...\n",
              "11291  11291  (please respond via email!)\\n\\nHas anybody act...\n",
              "11292  11292  Greetings!\\n   \\nI've had a bunch of problems ...\n",
              "11293  11293  \\n@===@                                       ...\n",
              "11294  11294  I had a catalog with membrane keypads, but I d...\n",
              "11295  11295  Oh boy, a little K-bike versus /2 scuffling? G...\n",
              "11296  11296  Hello to everybody,\\nI write here because I am...\n",
              "11297  11297  [reply to todamhyp@charles.unlv.edu (Brian M. ...\n",
              "11298  11298  This is exactly what I have heard before.  If ...\n",
              "11299  11299  \\nWhats the difference between a V.32bis modem...\n",
              "11300  11300  [why do babies get diseases, etc.]\\n\\n Here's ...\n",
              "11301  11301  I would like to know what people's opinions ar...\n",
              "11302  11302  You might want to clarify the 11 game winning ...\n",
              "11303  11303  \\nI totally agree with that sentiment.  But wh...\n",
              "11304  11304  \\nI agree with what Darren has to say here, bu...\n",
              "11305  11305  Ok people, I really need to sell this sampler ...\n",
              "11306  11306  Hi,\\n\\n  I am trying to write an X-windows bas...\n",
              "11307  11307  I'd like to share my thoughts on this topic of...\n",
              "11308  11308  My sunroof leaks.  I've always thought those t...\n",
              "11309  11309  Danny Rubenstein, an Israeli journalist, will ...\n",
              "11310  11310                                                 \\n\n",
              "11311  11311  \\nI agree.  Home runs off Clemens are always m...\n",
              "11312  11312  I used HP DeskJet with Orange Micros Grappler ...\n",
              "11313  11313                                        ^^^^^^\\n...\n",
              "\n",
              "[11314 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "jZY_8z6p-6V8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fff80ad0-d286-4bd6-d369-2231b9090719"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab   file.txt   nytimes_news_articles.txt\tstopwords.txt\r\n",
            "drive_PH  nltk_data  scikit_learn_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QZ3YiCG0-7O0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "27226b0a-b263-4424-90a9-405138a97515"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def paragraphs_to_sentece(pragraphs):\n",
        "    sentenses_list=[]\n",
        "    \n",
        "    for index_p in  range(len(pragraphs)):\n",
        "        #print(index_p)\n",
        "        #print(\"pppppppppppppppppppp\")\n",
        "        #print(pragraphs[index_p])\n",
        "        if pragraphs[index_p] is not None:\n",
        "          #print(\"setnences\")\n",
        "          #p1=txt_pragraphs(pragraphs[index_p])\n",
        "          setnences=pragraph_to_setnences(str(pragraphs[index_p]))\n",
        "          #print(\"sssssssssssssssssssssssssss\")\n",
        "          #print(\"setnences\")#,setnences)\n",
        "\n",
        "          for indexs in range(len(setnences)):\n",
        "              row=[]\n",
        "              #print(setnences)\n",
        "              row.append(index_p)\n",
        "              row.append(indexs)\n",
        "              row.append(setnences[indexs])\n",
        "              sentenses_list.append(row)\n",
        "    header_list=['index_P','index_sent','sentence']\n",
        "    df = pd.DataFrame(sentenses_list, columns=header_list)#, index=index)\n",
        "    #df\n",
        "\n",
        "    #print(sentenses_list)\n",
        "    df.to_csv(path_database+Sentences, encoding='utf-8', index=False)\n",
        "    #save_file_to_database(sentenses_list,path_database,\"Sentences.csv\",header_list)        \n",
        "    return df\n",
        "\n",
        "paragraphs_to_sentece(paragraphs.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WOwVVbU6TXFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "6d2c136d-b17a-45b2-e202-4e8083b1de4b"
      },
      "cell_type": "code",
      "source": [
        "setences=read_cvs_by_pands(path_database,Sentences,None,0)\n",
        "setences"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Well i'm not sure about the story nad it did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>What\\nI disagree with is your statement that t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>That is rediculous.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The U.S. media is\\nthe most pro-israeli media ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Having lived in Europe\\nI realize that inciden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The U.S. media as a whole seem to try to\\nigno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>The U.S. is subsidizing Israels existance and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>So I think\\nthat might be a reason they report...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>What is a shame is that in Austria, daily repo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>After all, look how the Jews are treating othe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>It is unfortunate.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>and actually accept hard\\natheism?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No, you need a little leap of faith, Jimmy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Your logic runs out\\nof steam!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Jim,\\n\\nSorry I can't pity you, Jim.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>And I'm sorry that you have these feelings of\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Oh well, just pretend that it will\\nall end ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Maybe if you start a new newsgroup,\\nalt.athei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Bye-Bye, Big Jim.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Don't forget your Flintstone's Chewables!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>:) \\n--\\nBake Timmons, III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Although I realize that principle is not one o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>If you want to continue this think tank charad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>You might have to start asking the\\nsame sort ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>You realize it\\nwould not work, as the Arab co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Everyone in this group recognizes that your st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ATT's last product in this area (a) was priced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Thus,\\naside from attempting to further legiti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128373</th>\n",
              "      <td>11309</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Berkeley campus.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128374</th>\n",
              "      <td>11309</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The talk is\\nsponsored by the Berkeley Israel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128375</th>\n",
              "      <td>11311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\nI agree.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128376</th>\n",
              "      <td>11311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Home runs off Clemens are always memorable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128377</th>\n",
              "      <td>11311</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Kinda like\\neclipses and hurricanes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128378</th>\n",
              "      <td>11311</td>\n",
              "      <td>3.0</td>\n",
              "      <td>They don't happen very often.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128379</th>\n",
              "      <td>11312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I used HP DeskJet with Orange Micros Grappler ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128380</th>\n",
              "      <td>11312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>But now I update system 6.0.5 to System7 with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128381</th>\n",
              "      <td>11312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Is the Grappler LS old ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128382</th>\n",
              "      <td>11312</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Can I use DeskJet on System7 ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128383</th>\n",
              "      <td>11312</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Please tell me how to use DeskJet on System7.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128384</th>\n",
              "      <td>11312</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Thank you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128385</th>\n",
              "      <td>11313</td>\n",
              "      <td>0.0</td>\n",
              "      <td>^^^^^^\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128386</th>\n",
              "      <td>11313</td>\n",
              "      <td>1.0</td>\n",
              "      <td>He scared the hell out of me when he came in\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128387</th>\n",
              "      <td>11313</td>\n",
              "      <td>2.0</td>\n",
              "      <td>On the other hand, the club though enough of B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128388</th>\n",
              "      <td>11313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>He seemed to be a very viable setup guy - but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128389</th>\n",
              "      <td>11313</td>\n",
              "      <td>4.0</td>\n",
              "      <td>I can just remember two years\\nago so well, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128390</th>\n",
              "      <td>11313</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I'm not that concerned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128391</th>\n",
              "      <td>11313</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Those guys have been relatively consistent ove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128392</th>\n",
              "      <td>11313</td>\n",
              "      <td>7.0</td>\n",
              "      <td>I expect them to come through just fine.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128393</th>\n",
              "      <td>11313</td>\n",
              "      <td>8.0</td>\n",
              "      <td>It's those guys that have not\\nbeen consistent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128394</th>\n",
              "      <td>11313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>This sounds like their old road unis.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128395</th>\n",
              "      <td>11313</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Pretty dull.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128396</th>\n",
              "      <td>11313</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Buttons or pullovers?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128397</th>\n",
              "      <td>11313</td>\n",
              "      <td>12.0</td>\n",
              "      <td>I'll check through my uniform book to see if t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128398</th>\n",
              "      <td>11313</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Well, we'll see.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128399</th>\n",
              "      <td>11313</td>\n",
              "      <td>14.0</td>\n",
              "      <td>I've got a Astros pullover shirt with the \"Ast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128400</th>\n",
              "      <td>11313</td>\n",
              "      <td>15.0</td>\n",
              "      <td>i\\ncan see why they might want that to change.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128401</th>\n",
              "      <td>11313</td>\n",
              "      <td>16.0</td>\n",
              "      <td>Gee, if they eliminate the\\norange, will they ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128402</th>\n",
              "      <td>11313</td>\n",
              "      <td>17.0</td>\n",
              "      <td>I saw a pinstripe version of an Astros cap and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128403 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index_P  index_sent                                           sentence\n",
              "0            0         0.0  Well i'm not sure about the story nad it did s...\n",
              "1            0         1.0  What\\nI disagree with is your statement that t...\n",
              "2            0         2.0                                That is rediculous.\n",
              "3            0         3.0  The U.S. media is\\nthe most pro-israeli media ...\n",
              "4            0         4.0  Having lived in Europe\\nI realize that inciden...\n",
              "5            0         5.0  The U.S. media as a whole seem to try to\\nigno...\n",
              "6            0         6.0  The U.S. is subsidizing Israels existance and ...\n",
              "7            0         7.0  So I think\\nthat might be a reason they report...\n",
              "8            0         8.0  What is a shame is that in Austria, daily repo...\n",
              "9            0         9.0  After all, look how the Jews are treating othe...\n",
              "10           0        10.0                                 It is unfortunate.\n",
              "11           1         0.0  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
              "12           1         1.0                 and actually accept hard\\natheism?\n",
              "13           1         2.0        No, you need a little leap of faith, Jimmy.\n",
              "14           1         3.0                     Your logic runs out\\nof steam!\n",
              "15           1         4.0               Jim,\\n\\nSorry I can't pity you, Jim.\n",
              "16           1         5.0  And I'm sorry that you have these feelings of\\...\n",
              "17           1         6.0  Oh well, just pretend that it will\\nall end ha...\n",
              "18           1         7.0  Maybe if you start a new newsgroup,\\nalt.athei...\n",
              "19           1         8.0                                  Bye-Bye, Big Jim.\n",
              "20           1         9.0          Don't forget your Flintstone's Chewables!\n",
              "21           1        10.0                         :) \\n--\\nBake Timmons, III\n",
              "22           2         0.0  Although I realize that principle is not one o...\n",
              "23           2         1.0  If you want to continue this think tank charad...\n",
              "24           2         2.0  You might have to start asking the\\nsame sort ...\n",
              "25           2         3.0  You realize it\\nwould not work, as the Arab co...\n",
              "26           2         4.0  Everyone in this group recognizes that your st...\n",
              "27           3         0.0  Notwithstanding all the legitimate fuss about ...\n",
              "28           3         1.0  ATT's last product in this area (a) was priced...\n",
              "29           3         2.0  Thus,\\naside from attempting to further legiti...\n",
              "...        ...         ...                                                ...\n",
              "128373   11309         2.0                                   Berkeley campus.\n",
              "128374   11309         3.0  The talk is\\nsponsored by the Berkeley Israel ...\n",
              "128375   11311         0.0                                         \\nI agree.\n",
              "128376   11311         1.0        Home runs off Clemens are always memorable.\n",
              "128377   11311         2.0               Kinda like\\neclipses and hurricanes.\n",
              "128378   11311         3.0                      They don't happen very often.\n",
              "128379   11312         0.0  I used HP DeskJet with Orange Micros Grappler ...\n",
              "128380   11312         1.0  But now I update system 6.0.5 to System7 with ...\n",
              "128381   11312         2.0                           Is the Grappler LS old ?\n",
              "128382   11312         3.0                     Can I use DeskJet on System7 ?\n",
              "128383   11312         4.0      Please tell me how to use DeskJet on System7.\n",
              "128384   11312         5.0                                          Thank you\n",
              "128385   11313         0.0                                        ^^^^^^\\n...\n",
              "128386   11313         1.0  He scared the hell out of me when he came in\\n...\n",
              "128387   11313         2.0  On the other hand, the club though enough of B...\n",
              "128388   11313         3.0  He seemed to be a very viable setup guy - but ...\n",
              "128389   11313         4.0  I can just remember two years\\nago so well, th...\n",
              "128390   11313         5.0                            I'm not that concerned.\n",
              "128391   11313         6.0  Those guys have been relatively consistent ove...\n",
              "128392   11313         7.0           I expect them to come through just fine.\n",
              "128393   11313         8.0  It's those guys that have not\\nbeen consistent...\n",
              "128394   11313         9.0              This sounds like their old road unis.\n",
              "128395   11313        10.0                                       Pretty dull.\n",
              "128396   11313        11.0                              Buttons or pullovers?\n",
              "128397   11313        12.0  I'll check through my uniform book to see if t...\n",
              "128398   11313        13.0                                   Well, we'll see.\n",
              "128399   11313        14.0  I've got a Astros pullover shirt with the \"Ast...\n",
              "128400   11313        15.0     i\\ncan see why they might want that to change.\n",
              "128401   11313        16.0  Gee, if they eliminate the\\norange, will they ...\n",
              "128402   11313        17.0  I saw a pinstripe version of an Astros cap and...\n",
              "\n",
              "[128403 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "y3_OiNTTB9Lw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "def  sentece_Not_stop_word(setences):\n",
        "    #words_list=[]\n",
        "    sentenses_list=[]\n",
        "    \n",
        "    for index_s in  range(len(setences)):\n",
        "            \n",
        "          #print(\"Sentence No. \",index_s,\": \",setences.loc[index_s]['sentence'],\"\\n\")\n",
        "          words=remove_stopword_sentences(str(setences.loc[index_s]['sentence']))\n",
        "          wordsent=''\n",
        "          row=[]\n",
        "          \n",
        "\n",
        "          row.append(setences.loc[index_s]['index_P'])\n",
        "          row.append(setences.loc[index_s]['index_sent'])\n",
        "          row.append(words)\n",
        "          sentenses_list.append(row)\n",
        "    header_list=['index_P','index_sent','words_not_stop']\n",
        "    df = pd.DataFrame(sentenses_list, columns=header_list)#, index=index)\n",
        "    #df\n",
        "\n",
        "    #print(sentenses_list)\n",
        "    df.to_csv(path_database+Sentences_not_stops, encoding='utf-8', index=False)\n",
        "    #save_file_to_database(sentenses_list,path_database,\"Sentences.csv\",header_list)        \n",
        "    return df\n",
        "\n",
        "sentece_Not_stop_word(setences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "75LvkDP6CONE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "this function for compute lesk of word in sentence\n",
        "'''\n",
        "\n",
        "def lesk_word_sentence(sentence,word):\n",
        "    from nltk.wsd import lesk\n",
        "    lesk_synset=''\n",
        "    #lesks= []\n",
        "    #for word in words:\n",
        "    #disambiguated=lesk(context_sentence=sentence, ambiguous_word=word)\n",
        "    disambiguated=lesk(sentence,word, 'n')\n",
        "    #print(disambiguated)\n",
        "    #if disambiguated is not None:\n",
        "    lesk_synset=disambiguated\n",
        "    #else:\n",
        "    #lesk_synset=0\n",
        "    #print(\"Word is: \",word,\"\\n LESK: \",lesk(sentence,word, 'n'),\"\\n Sentence: \",sentence )\n",
        "        \n",
        "    return lesk_synset\n",
        "\n",
        "#lesk(\"Computer science is a discipline that spans theory and practice\",\"science\")\n",
        "\n",
        "#sent = 'people should be able to marry a person of their choice'.split()\n",
        "#lesk(sent, 'able')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AecJWi87X8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "7e3d3c61-ba4d-4d23-ce5c-a6d5e319d3f7"
      },
      "cell_type": "code",
      "source": [
        "df_Sentences_not_stops=read_cvs_by_pands(path_database,Sentences_not_stops,None,0)\n",
        "df_Sentences_not_stops"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>words_not_stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['Well', \"i'm\", 'sure', 'story', 'nad', 'seem'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['disagree', 'statement', 'U', 'Media', 'ruin'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['rediculous']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['U', 'media', 'pro', 'israeli', 'media', 'wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['lived', 'Europe', 'realize', 'incidences', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>['U', 'subsidizing', 'Israels', 'existance', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>['think', 'might', 'reason', 'report', 'clearl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['look', 'Jews', 'treating', 'races', 'got', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['unfortunate']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['Yeah', 'expect', 'people', 'read', 'FAQ', 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['actually', 'accept', 'hard', 'atheism']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['need', 'little', 'leap', 'faith', 'Jimmy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['logic', 'runs', 'steam']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['Jim', 'Sorry', \"can't\", 'pity', 'Jim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>['Oh', 'well', 'pretend', 'end', 'happily', 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>['Bye', 'Bye', 'Big', 'Jim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['forget', \"Flintstone's\", 'Chewables']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['Bake', 'Timmons', 'III']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['Although', 'realize', 'principle', 'one', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['want', 'continue', 'think', 'tank', 'charade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['Everyone', 'group', 'recognizes', 'stupid', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[\"ATT's\", 'last', 'product', 'area', 'priced',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['Thus', 'aside', 'attempting', 'legitimize', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128373</th>\n",
              "      <td>11309</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['Berkeley', 'campus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128374</th>\n",
              "      <td>11309</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['talk', 'sponsored', 'Berkeley', 'Israel', 'A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128375</th>\n",
              "      <td>11311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['agree']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128376</th>\n",
              "      <td>11311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['Home', 'runs', 'Clemens', 'always', 'memorab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128377</th>\n",
              "      <td>11311</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['Kinda', 'like', 'eclipses', 'hurricanes']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128378</th>\n",
              "      <td>11311</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128379</th>\n",
              "      <td>11312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['used', 'HP', 'DeskJet', 'Orange', 'Micros', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128380</th>\n",
              "      <td>11312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['update', 'system', 'System7', 'Kanji', 'Talk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128381</th>\n",
              "      <td>11312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128382</th>\n",
              "      <td>11312</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['use', 'DeskJet', 'System7']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128383</th>\n",
              "      <td>11312</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['Please', 'tell', 'use', 'DeskJet', 'System7']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128384</th>\n",
              "      <td>11312</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128385</th>\n",
              "      <td>11313</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['argument', 'Murphy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128386</th>\n",
              "      <td>11313</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128387</th>\n",
              "      <td>11313</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128388</th>\n",
              "      <td>11313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['seemed', 'viable', 'setup', 'guy', 'guess', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128389</th>\n",
              "      <td>11313</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128390</th>\n",
              "      <td>11313</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[\"I'm\", 'concerned']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128391</th>\n",
              "      <td>11313</td>\n",
              "      <td>6.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128392</th>\n",
              "      <td>11313</td>\n",
              "      <td>7.0</td>\n",
              "      <td>['expect', 'come', 'fine']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128393</th>\n",
              "      <td>11313</td>\n",
              "      <td>8.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128394</th>\n",
              "      <td>11313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['sounds', 'like', 'old', 'road', 'unis']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128395</th>\n",
              "      <td>11313</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['Pretty', 'dull']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128396</th>\n",
              "      <td>11313</td>\n",
              "      <td>11.0</td>\n",
              "      <td>['Buttons', 'pullovers']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128397</th>\n",
              "      <td>11313</td>\n",
              "      <td>12.0</td>\n",
              "      <td>[\"I'll\", 'check', 'uniform', 'book', 'see', \"t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128398</th>\n",
              "      <td>11313</td>\n",
              "      <td>13.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128399</th>\n",
              "      <td>11313</td>\n",
              "      <td>14.0</td>\n",
              "      <td>[\"I've\", 'got', 'Astros', 'pullover', 'shirt',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128400</th>\n",
              "      <td>11313</td>\n",
              "      <td>15.0</td>\n",
              "      <td>['see', 'might', 'want', 'change']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128401</th>\n",
              "      <td>11313</td>\n",
              "      <td>16.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128402</th>\n",
              "      <td>11313</td>\n",
              "      <td>17.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128403 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index_P  index_sent                                     words_not_stop\n",
              "0            0         0.0  ['Well', \"i'm\", 'sure', 'story', 'nad', 'seem'...\n",
              "1            0         1.0  ['disagree', 'statement', 'U', 'Media', 'ruin'...\n",
              "2            0         2.0                                     ['rediculous']\n",
              "3            0         3.0  ['U', 'media', 'pro', 'israeli', 'media', 'wor...\n",
              "4            0         4.0  ['lived', 'Europe', 'realize', 'incidences', '...\n",
              "5            0         5.0                                                 []\n",
              "6            0         6.0  ['U', 'subsidizing', 'Israels', 'existance', '...\n",
              "7            0         7.0  ['think', 'might', 'reason', 'report', 'clearl...\n",
              "8            0         8.0                                                 []\n",
              "9            0         9.0  ['look', 'Jews', 'treating', 'races', 'got', '...\n",
              "10           0        10.0                                    ['unfortunate']\n",
              "11           1         0.0  ['Yeah', 'expect', 'people', 'read', 'FAQ', 'e...\n",
              "12           1         1.0          ['actually', 'accept', 'hard', 'atheism']\n",
              "13           1         2.0       ['need', 'little', 'leap', 'faith', 'Jimmy']\n",
              "14           1         3.0                         ['logic', 'runs', 'steam']\n",
              "15           1         4.0           ['Jim', 'Sorry', \"can't\", 'pity', 'Jim']\n",
              "16           1         5.0                                                 []\n",
              "17           1         6.0  ['Oh', 'well', 'pretend', 'end', 'happily', 'e...\n",
              "18           1         7.0                                                 []\n",
              "19           1         8.0                       ['Bye', 'Bye', 'Big', 'Jim']\n",
              "20           1         9.0            ['forget', \"Flintstone's\", 'Chewables']\n",
              "21           1        10.0                         ['Bake', 'Timmons', 'III']\n",
              "22           2         0.0  ['Although', 'realize', 'principle', 'one', 's...\n",
              "23           2         1.0  ['want', 'continue', 'think', 'tank', 'charade...\n",
              "24           2         2.0                                                 []\n",
              "25           2         3.0                                                 []\n",
              "26           2         4.0  ['Everyone', 'group', 'recognizes', 'stupid', ...\n",
              "27           3         0.0                                                 []\n",
              "28           3         1.0  [\"ATT's\", 'last', 'product', 'area', 'priced',...\n",
              "29           3         2.0  ['Thus', 'aside', 'attempting', 'legitimize', ...\n",
              "...        ...         ...                                                ...\n",
              "128373   11309         2.0                             ['Berkeley', 'campus']\n",
              "128374   11309         3.0  ['talk', 'sponsored', 'Berkeley', 'Israel', 'A...\n",
              "128375   11311         0.0                                          ['agree']\n",
              "128376   11311         1.0  ['Home', 'runs', 'Clemens', 'always', 'memorab...\n",
              "128377   11311         2.0        ['Kinda', 'like', 'eclipses', 'hurricanes']\n",
              "128378   11311         3.0                                                 []\n",
              "128379   11312         0.0  ['used', 'HP', 'DeskJet', 'Orange', 'Micros', ...\n",
              "128380   11312         1.0  ['update', 'system', 'System7', 'Kanji', 'Talk...\n",
              "128381   11312         2.0                                                 []\n",
              "128382   11312         3.0                      ['use', 'DeskJet', 'System7']\n",
              "128383   11312         4.0    ['Please', 'tell', 'use', 'DeskJet', 'System7']\n",
              "128384   11312         5.0                                                 []\n",
              "128385   11313         0.0                             ['argument', 'Murphy']\n",
              "128386   11313         1.0                                                 []\n",
              "128387   11313         2.0                                                 []\n",
              "128388   11313         3.0  ['seemed', 'viable', 'setup', 'guy', 'guess', ...\n",
              "128389   11313         4.0                                                 []\n",
              "128390   11313         5.0                               [\"I'm\", 'concerned']\n",
              "128391   11313         6.0                                                 []\n",
              "128392   11313         7.0                         ['expect', 'come', 'fine']\n",
              "128393   11313         8.0                                                 []\n",
              "128394   11313         9.0          ['sounds', 'like', 'old', 'road', 'unis']\n",
              "128395   11313        10.0                                 ['Pretty', 'dull']\n",
              "128396   11313        11.0                           ['Buttons', 'pullovers']\n",
              "128397   11313        12.0  [\"I'll\", 'check', 'uniform', 'book', 'see', \"t...\n",
              "128398   11313        13.0                                                 []\n",
              "128399   11313        14.0  [\"I've\", 'got', 'Astros', 'pullover', 'shirt',...\n",
              "128400   11313        15.0                 ['see', 'might', 'want', 'change']\n",
              "128401   11313        16.0                                                 []\n",
              "128402   11313        17.0                                                 []\n",
              "\n",
              "[128403 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "RIfVEgdaCcsC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e9b04a43-24fb-4ca6-a721-b3bdcd8a320a"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "def sent_lesks():\n",
        "    df_Sentences=read_cvs_by_pands(path_database,Sentences,None,0)\n",
        "    df_Sentences_not_stops=read_cvs_by_pands(path_database,Sentences_not_stops,None,0)\n",
        "    sentences=df_Sentences.sentence\n",
        "    words_not_stop=df_Sentences_not_stops.words_not_stop#[0]#['words_not_stop'][0]\n",
        "    lesk_df_list=[]\n",
        "    file=open('./file.txt', 'a+')\n",
        "    #print(len(df_Sentences))\n",
        "    #print(len(df_Sentences_not_stops))\n",
        "    for i in range(len(df_Sentences)):\n",
        "        lesks=[]\n",
        "        lesks_name=[]\n",
        "        row=[]\n",
        "        if words_not_stop[i]!='[]':\n",
        "\n",
        "            words_not_stop[i]=words_not_stop[i].replace(\"'\",'').replace(\"[\",'').replace(\"]\",'')\n",
        "            sentences[i]=sentences[i].replace(\"'\",'').replace(\"[\",'').replace(\"]\",'')       \n",
        "            words_not_stop_list=words_not_stop[i].split(',')\n",
        "            #print(words_not_stop_list)\n",
        "            #print(sentences[i])\n",
        "            for word in words_not_stop_list:\n",
        "                #print(word)\n",
        "                l=lesk_word_sentence(sentences[i],word)\n",
        "                #print(\"l\",l)\n",
        "                if l is not None:\n",
        "                    lesks.append(l)\n",
        "                    lesks_name.append(l.name())\n",
        "        #print(\"888888888888888888888888888888888888888888\")\n",
        "        row.append(df_Sentences_not_stops.index_P[i])\n",
        "        row.append(df_Sentences_not_stops.index_sent[i])\n",
        "        row.append(lesks)\n",
        "        row.append(lesks_name)\n",
        "        lesk_df_list.append(row)\n",
        "        #print(i)\n",
        "        file.write(str(i))\n",
        "\n",
        "    #print(lesk_df_list)\n",
        "    header_list=['index_P','index_sent','lesks','lesks_name']\n",
        "    df = pd.DataFrame(lesk_df_list, columns=header_list)\n",
        "    \n",
        "    df.to_csv(path_database+\"lesks.csv\", encoding='utf-8', index=False)  \n",
        "    #return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sent_lesks()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zRzbslo-Cv0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "2a58afc1-fbe2-4b0f-8191-23cb99e09f13"
      },
      "cell_type": "code",
      "source": [
        "l=read_cvs_by_pands(path_database,'lesks.csv',None,0)\n",
        "l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>lesks</th>\n",
              "      <th>lesks_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[Synset('washington.n.05')]</td>\n",
              "      <td>['washington.n.05']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>[Synset('pitching.n.01')]</td>\n",
              "      <td>['pitching.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>[Synset('large.n.01')]</td>\n",
              "      <td>['large.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>[Synset('second_gear.n.01')]</td>\n",
              "      <td>['second_gear.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>[Synset('collins.n.02')]</td>\n",
              "      <td>['collins.n.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>59</td>\n",
              "      <td>49</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>59</td>\n",
              "      <td>50</td>\n",
              "      <td>[Synset('football.n.01')]</td>\n",
              "      <td>['football.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1992</th>\n",
              "      <td>59</td>\n",
              "      <td>51</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>59</td>\n",
              "      <td>52</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>59</td>\n",
              "      <td>53</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>59</td>\n",
              "      <td>54</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>59</td>\n",
              "      <td>55</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>[Synset('store.n.02')]</td>\n",
              "      <td>['store.n.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>[Synset('dinner.n.02')]</td>\n",
              "      <td>['dinner.n.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000</th>\n",
              "      <td>60</td>\n",
              "      <td>3</td>\n",
              "      <td>[Synset('official.n.02')]</td>\n",
              "      <td>['official.n.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>60</td>\n",
              "      <td>4</td>\n",
              "      <td>[Synset('interim.n.01')]</td>\n",
              "      <td>['interim.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>[Synset('adjutant.n.01')]</td>\n",
              "      <td>['adjutant.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>60</td>\n",
              "      <td>6</td>\n",
              "      <td>[Synset('small.n.02')]</td>\n",
              "      <td>['small.n.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>60</td>\n",
              "      <td>7</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>60</td>\n",
              "      <td>8</td>\n",
              "      <td>[Synset('billionaire.n.01')]</td>\n",
              "      <td>['billionaire.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>60</td>\n",
              "      <td>9</td>\n",
              "      <td>[Synset('dinner.n.02')]</td>\n",
              "      <td>['dinner.n.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007</th>\n",
              "      <td>60</td>\n",
              "      <td>10</td>\n",
              "      <td>[Synset('mister.n.01')]</td>\n",
              "      <td>['mister.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008</th>\n",
              "      <td>60</td>\n",
              "      <td>11</td>\n",
              "      <td>[Synset('spokesman.n.01')]</td>\n",
              "      <td>['spokesman.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009</th>\n",
              "      <td>60</td>\n",
              "      <td>12</td>\n",
              "      <td>[Synset('last.n.08')]</td>\n",
              "      <td>['last.n.08']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010</th>\n",
              "      <td>60</td>\n",
              "      <td>13</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011</th>\n",
              "      <td>60</td>\n",
              "      <td>14</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>60</td>\n",
              "      <td>15</td>\n",
              "      <td>[Synset('mister.n.01')]</td>\n",
              "      <td>['mister.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013</th>\n",
              "      <td>60</td>\n",
              "      <td>16</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>[Synset('mrs.n.01')]</td>\n",
              "      <td>['mrs.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>60</td>\n",
              "      <td>19</td>\n",
              "      <td>[Synset('mister.n.01')]</td>\n",
              "      <td>['mister.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>[Synset('last.n.08')]</td>\n",
              "      <td>['last.n.08']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>60</td>\n",
              "      <td>21</td>\n",
              "      <td>[Synset('friday.n.01')]</td>\n",
              "      <td>['friday.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>60</td>\n",
              "      <td>22</td>\n",
              "      <td>[Synset('washington.n.05')]</td>\n",
              "      <td>['washington.n.05']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2020 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index_P  index_sent                         lesks            lesks_name\n",
              "0           0           0   [Synset('washington.n.05')]   ['washington.n.05']\n",
              "1           0           1                            []                    []\n",
              "2           0           2                            []                    []\n",
              "3           0           3                            []                    []\n",
              "4           0           4                            []                    []\n",
              "5           0           5     [Synset('pitching.n.01')]     ['pitching.n.01']\n",
              "6           0           6        [Synset('large.n.01')]        ['large.n.01']\n",
              "7           0           7                            []                    []\n",
              "8           0           8                            []                    []\n",
              "9           0           9                            []                    []\n",
              "10          0          10                            []                    []\n",
              "11          0          11                            []                    []\n",
              "12          0          12                            []                    []\n",
              "13          0          13                            []                    []\n",
              "14          0          14                            []                    []\n",
              "15          0          15                            []                    []\n",
              "16          0          16                            []                    []\n",
              "17          0          17                            []                    []\n",
              "18          0          18                            []                    []\n",
              "19          0          19                            []                    []\n",
              "20          0          20                            []                    []\n",
              "21          0          21                            []                    []\n",
              "22          0          22                            []                    []\n",
              "23          0          23                            []                    []\n",
              "24          0          24                            []                    []\n",
              "25          0          25                            []                    []\n",
              "26          0          26                            []                    []\n",
              "27          0          27  [Synset('second_gear.n.01')]  ['second_gear.n.01']\n",
              "28          0          28      [Synset('collins.n.02')]      ['collins.n.02']\n",
              "29          0          29                            []                    []\n",
              "...       ...         ...                           ...                   ...\n",
              "1990       59          49                            []                    []\n",
              "1991       59          50     [Synset('football.n.01')]     ['football.n.01']\n",
              "1992       59          51                            []                    []\n",
              "1993       59          52                            []                    []\n",
              "1994       59          53                            []                    []\n",
              "1995       59          54                            []                    []\n",
              "1996       59          55                            []                    []\n",
              "1997       60           0        [Synset('store.n.02')]        ['store.n.02']\n",
              "1998       60           1       [Synset('dinner.n.02')]       ['dinner.n.02']\n",
              "1999       60           2                            []                    []\n",
              "2000       60           3     [Synset('official.n.02')]     ['official.n.02']\n",
              "2001       60           4      [Synset('interim.n.01')]      ['interim.n.01']\n",
              "2002       60           5     [Synset('adjutant.n.01')]     ['adjutant.n.01']\n",
              "2003       60           6        [Synset('small.n.02')]        ['small.n.02']\n",
              "2004       60           7                            []                    []\n",
              "2005       60           8  [Synset('billionaire.n.01')]  ['billionaire.n.01']\n",
              "2006       60           9       [Synset('dinner.n.02')]       ['dinner.n.02']\n",
              "2007       60          10       [Synset('mister.n.01')]       ['mister.n.01']\n",
              "2008       60          11    [Synset('spokesman.n.01')]    ['spokesman.n.01']\n",
              "2009       60          12         [Synset('last.n.08')]         ['last.n.08']\n",
              "2010       60          13                            []                    []\n",
              "2011       60          14                            []                    []\n",
              "2012       60          15       [Synset('mister.n.01')]       ['mister.n.01']\n",
              "2013       60          16                            []                    []\n",
              "2014       60          17                            []                    []\n",
              "2015       60          18          [Synset('mrs.n.01')]          ['mrs.n.01']\n",
              "2016       60          19       [Synset('mister.n.01')]       ['mister.n.01']\n",
              "2017       60          20         [Synset('last.n.08')]         ['last.n.08']\n",
              "2018       60          21       [Synset('friday.n.01')]       ['friday.n.01']\n",
              "2019       60          22   [Synset('washington.n.05')]   ['washington.n.05']\n",
              "\n",
              "[2020 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "r-viOg2QGplO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "efe676a3-255a-41ae-c40d-8aed8ded2c50"
      },
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab   file.txt   nytimes_news_articles.txt\tstopwords.txt\r\n",
            "drive_PH  nltk_data  scikit_learn_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vNiJw3RnG2tA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of fetch_20newsgroups.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fatmas1982/fh2017/blob/master/Copy_of_fetch_20newsgroups5.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "me14sBCEuffI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "f5bb81ce-f685-43ca-e629-273eb413c24b"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot') \n",
        "import numpy as np\n",
        "import scipy.stats.stats as st\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "#from stemming.porter2 import stem\n",
        "from nltk import PorterStemmer\n",
        "from nltk.stem.porter import *\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from string import digits\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import csv\n",
        "\n",
        "import re\n",
        "from nltk import word_tokenize\n",
        "import string\n",
        "!pip install gensim\n",
        "import  gensim.models as md\n",
        "from gensim.models.phrases import Phrases, Phraser\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 15.0MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ed/8160213941beab9bf5c352d29111e2e0cd0e580a52e902bf3bef8559fa86/boto3-1.7.14-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 19.0MB/s \n",
            "\u001b[?25hCollecting botocore<1.11.0,>=1.10.14 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/b3/28c1451630d84c3d2cd54475aff89f2ca75efd035b4325af628f67536a7c/botocore-1.10.14-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.2MB 8.6MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.11.0,>=1.10.14->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.14->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.48.0 boto3-1.7.14 botocore-1.10.14 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GvYYCnMyytqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "b85aa086-5462-4d68-bc1f-6db1393394ce"
      },
      "cell_type": "code",
      "source": [
        "!pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\r\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.12)\r\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.2)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (3.4.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aikWxQjx05u4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2327
        },
        "outputId": "5dfeb02a-871f-423d-cdc2-49187d53602f"
      },
      "cell_type": "code",
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18298 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.1_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.1) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.1) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpsxhwkczt/pubring.gpg' created\n",
            "gpg: /tmp/tmpsxhwkczt/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19706 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fzwzSluP1BRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SR-ozY_l1OaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "256215a1-1c01-4dbe-c901-61f51160262f"
      },
      "cell_type": "code",
      "source": [
        "#https://colab.research.google.com/notebook#fileId=1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q&scrollTo=c99EvWo1s9-x\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7VU7uSU82Uwy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNP8Uhv525hA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive_PH\n",
        "!google-drive-ocamlfuse drive_PH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqDmfjblsCgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7e502be2-9e40-4ab8-8191-7bf8ff4c41a0"
      },
      "cell_type": "code",
      "source": [
        "!ls 'drive_PH/Colab Notebooks'"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copy of colab_topicmodeling.ipynb\t\t  NYT_output\r\n",
            "Copy of fetch_20newsgroups.ipynb\t\t  pragraph_index_20.csv\r\n",
            "Copy of new-york-times-articles (9b3b30f2).ipynb  pragraph_index.csv\r\n",
            "Copy of new-york-times-articles.ipynb\t\t  Sentences_20.csv\r\n",
            "fetch_20newsgroups.ipynb\t\t\t  Sentences.csv\r\n",
            "input\t\t\t\t\t\t  Sentences_not_stops_20.csv\r\n",
            "lesks.csv\t\t\t\t\t  Sentences_not_stops.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TRIVr4TKuzbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_database='./drive_PH/Colab Notebooks/' \n",
        "path_stop_word=path_database+'input/stopwords/'\n",
        "\n",
        "pragraph_index='pragraph_index_20.csv'\n",
        "Sentences='Sentences_20.csv'\n",
        "Sentences_not_stops='Sentences_not_stops_20.csv'\n",
        "lesk='lesk_20.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IOduIEN0thrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d64a47b7-16bd-4dc3-9027-f529998662b3"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(path_stop_word)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stopwords.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "FzyPK8SaloNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "40414644-681b-413c-e3e7-146b9c9be7cf"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0IcKS15EmGUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2d7fa663-2418-4af8-9bcf-4bdb5c712d20"
      },
      "cell_type": "code",
      "source": [
        "documents[0]\n",
        "dataset.filenames"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.mideast/76141',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/alt.atheism/53281',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.mideast/76350',\n",
              "       ...,\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.baseball/105105',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51575',\n",
              "       '/content/scikit_learn_data/20news_home/20news-bydate-train/rec.sport.baseball/104908'],\n",
              "      dtype='<U89')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "yOs-pWWeuaMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write Excell sheet\n",
        "'''\n",
        "def save_file_to_database(data_rows,path_database,file_databbase,header_list):#header_list=['index','text']\n",
        "    outfile = open(path_database+file_databbase,'w')\n",
        "    writer=csv.writer(outfile)\n",
        "    #header_list=['uuid','paragraph','doc_id']\n",
        "    i=0\n",
        "    for line in data_rows:\n",
        "        row=[i,line]#,'paragraph no.'+str(i)]\n",
        "        if i==0:\n",
        "            \n",
        "            writer.writerow(header_list)\n",
        "            writer.writerow(row)\n",
        "        else:\n",
        "            #print('ff')\n",
        "            writer.writerow(row)\n",
        "        i+= 1\n",
        "        #outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVChg9cLwyD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_cvs_by_pands(path_database,file_databbase,index_col, header):\n",
        "    return pd.read_csv(path_database+file_databbase,index_col=index_col,header=header)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrjPdQNfwy3K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pragraph_to_setnences(str):\n",
        "    return sent_tokenize(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVlUCEHeRxxC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def txt_pragraphs(str):\n",
        "    pragraphs = str.split(\"\\n\\n\")\n",
        "    return pragraphs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KwUghKOWPuty",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrY0paf2w7LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_text_from_database(path_database,file_databbase):\n",
        "    queue_paragraph=[]\n",
        "    #f = open(sys.argv[1], 'rt')\n",
        "    outfile = open(path_database+file_databbase,'rt')\n",
        "    try:\n",
        "                \n",
        "        reader=csv.reader(outfile)\n",
        "        for row in reader:\n",
        "            queue_paragraph.append(row)\n",
        "            #print (row)\n",
        "    finally:\n",
        "        print (\"row\")\n",
        "        outfile.close()\n",
        "        \n",
        "    return queue_paragraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEoC0O_-w7C2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stopwords_list():\n",
        "    stopwordsFile = open(path_stop_word+'stopwords.txt')\n",
        "    stopwordsFile.seek(0)\n",
        "    stopwordsV1 = stopwordsFile.readlines()\n",
        "    stopwordsV2 = []\n",
        "    for sent in stopwordsV1:\n",
        "        sent.replace('\\n', '')\n",
        "        new_word = sent[0:len(sent) - 1]\n",
        "        stopwordsV2.append(new_word.lower())\n",
        "    return stopwordsV2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYP_EfTsw62c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_stop_words = ['the', 'that', 'to', 'as', 'there', 'has', 'and', 'or', 'is', 'not', 'a', 'of', 'but', 'in', 'by', 'on', 'are', 'it', 'if','what','where','how','when']\n",
        "new_stop_words2=['--','i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now','even','until','then','must']\n",
        "numbers=[1,2,3,4,5,6,7,8,9]\n",
        "stopwordsV2=stopwords_list()\n",
        "#stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "def remove_stopword_sentences(str):\n",
        "   \n",
        "            \n",
        "    list_word=[]\n",
        "    tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
        "    \n",
        "    words=tokenizer.tokenize(str)\n",
        "    for word in words:\n",
        "        new_word = word.encode('ascii', 'ignore').decode('utf-8')\n",
        "        if new_word != '':\n",
        "    \n",
        "            english_stops = set(stopwords.words('english'))\n",
        "           \n",
        "            list_word=[new_word for new_word in words if new_word.lower() not in english_stops\n",
        "                       and new_word.lower() not in new_stop_words \n",
        "                       and new_word.lower() not in new_stop_words2 \n",
        "                       and  not new_word.lower().isdigit() \n",
        "                       and new_word.lower() not in digits \n",
        "                       and new_word.lower() not in  numbers and word.lower() not in stopwordsV2\n",
        "                       and new_word.lower() not in string.punctuation]\n",
        "    \n",
        "  \n",
        "    \n",
        "    return list_word#(stem(setem_word for setem_word in  ([word for word in words if word not in english_stops and word not in new_stop_words])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZ3YiCG0-7O0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def paragraphs_to_sentece(pragraphs):\n",
        "    sentenses_list=[]\n",
        "    \n",
        "    for index_p in  range(len(pragraphs)):\n",
        "        #print(index_p)\n",
        "        #print(\"pppppppppppppppppppp\")\n",
        "        #print(pragraphs[index_p])\n",
        "        if pragraphs[index_p] is not None:\n",
        "          #print(\"setnences\")\n",
        "          #p1=txt_pragraphs(pragraphs[index_p])\n",
        "          setnences=pragraph_to_setnences(str(pragraphs[index_p]))\n",
        "          #print(\"sssssssssssssssssssssssssss\")\n",
        "          #print(\"setnences\")#,setnences)\n",
        "\n",
        "          for indexs in range(len(setnences)):\n",
        "              row=[]\n",
        "              #print(setnences)\n",
        "              row.append(index_p)\n",
        "              row.append(indexs)\n",
        "              row.append(setnences[indexs])\n",
        "              sentenses_list.append(row)\n",
        "    header_list=['index_P','index_sent','sentence']\n",
        "    df = pd.DataFrame(sentenses_list, columns=header_list)#, index=index)\n",
        "    #df\n",
        "\n",
        "    #print(sentenses_list)\n",
        "    df.to_csv(path_database+Sentences, encoding='utf-8', index=False)\n",
        "    #save_file_to_database(sentenses_list,path_database,\"Sentences.csv\",header_list)        \n",
        "    return df\n",
        "\n",
        "#paragraphs_to_sentece(paragraphs.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wC8vNEEaw6hE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls nytimes_news_articles.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3_OiNTTB9Lw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "def  sentece_Not_stop_word(setences):\n",
        "    #words_list=[]\n",
        "    sentenses_list=[]\n",
        "    \n",
        "    for index_s in  range(len(setences)):\n",
        "            \n",
        "          #print(\"Sentence No. \",index_s,\": \",setences.loc[index_s]['sentence'],\"\\n\")\n",
        "          words=remove_stopword_sentences(str(setences.loc[index_s]['sentence']))\n",
        "          wordsent=''\n",
        "          row=[]\n",
        "          \n",
        "\n",
        "          row.append(setences.loc[index_s]['index_P'])\n",
        "          row.append(setences.loc[index_s]['index_sent'])\n",
        "          row.append(words)\n",
        "          sentenses_list.append(row)\n",
        "    header_list=['index_P','index_sent','words_not_stop']\n",
        "    df = pd.DataFrame(sentenses_list, columns=header_list)#, index=index)\n",
        "    #df\n",
        "\n",
        "    #print(sentenses_list)\n",
        "    df.to_csv(path_database+Sentences_not_stops, encoding='utf-8', index=False)\n",
        "    #save_file_to_database(sentenses_list,path_database,\"Sentences.csv\",header_list)        \n",
        "    return df\n",
        "\n",
        "#sentece_Not_stop_word(setences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64fBKXlnBYIa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def courps_to_CSV_docs():\n",
        "    #Reading the news articles file\n",
        "    nyTimesFile = open('./nytimes_news_articles.txt', encoding='latin-1')\n",
        "    nyTimesFile.seek(0)\n",
        "    nyTimesV1 = nyTimesFile.readlines()\n",
        "    nyTimesTemp = []\n",
        "    nyTimesURL = []\n",
        "\n",
        "    for i in range(0, len(nyTimesV1)-1):\n",
        "        if re.findall('URL', nyTimesV1[i]) == []:\n",
        "            sent = sent + nyTimesV1[i]\n",
        "            if (re.findall('URL', nyTimesV1[i+1]) != []) and (i+1 < len(nyTimesV1)):\n",
        "                nyTimesTemp.append(sent.strip())\n",
        "        else:\n",
        "            sent = ''\n",
        "            nyTimesURL.append(nyTimesV1[i])\n",
        "\n",
        "    for i in range(0, len(nyTimesTemp)):\n",
        "        nyTimesTemp[i] = nyTimesTemp[i]+'articleID'+str(i)\n",
        "    print(len(nyTimesTemp))\n",
        "    header_list=['index','text']\n",
        "    save_file_to_database(nyTimesTemp,path_database,pragraph_index,header_list)\n",
        "    '''for i in range(1):\n",
        "        print(i,\"============================================\")\n",
        "        print(\"============================================\")'''\n",
        "    #nytimes = preProcessor(nyTimesTemp)\n",
        "    print(\"============================================\")\n",
        "    #print(nytimes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qxfC-Owjmby8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "header_list=['index','text']\n",
        "#save_file_to_database(documents,'/',pragraph_index,header_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFmp8dmuP0hs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save_file_to_database(documents,path_database,pragraph_index,header_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36a6-R2FBcZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#courps_to_CSV_docs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXOY0cobvZEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "paragraphs=read_cvs_by_pands(path_database,pragraph_index,None,0)\n",
        "paragraphs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jZY_8z6p-6V8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WOwVVbU6TXFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "b38514a7-8e86-468e-9986-7c29971bdc50"
      },
      "cell_type": "code",
      "source": [
        "setences=read_cvs_by_pands(path_database,Sentences,None,0)\n",
        "setences"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Well i'm not sure about the story nad it did s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>What\\nI disagree with is your statement that t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>That is rediculous.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The U.S. media is\\nthe most pro-israeli media ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Having lived in Europe\\nI realize that inciden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>The U.S. media as a whole seem to try to\\nigno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>The U.S. is subsidizing Israels existance and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>So I think\\nthat might be a reason they report...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>What is a shame is that in Austria, daily repo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>After all, look how the Jews are treating othe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>It is unfortunate.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>and actually accept hard\\natheism?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No, you need a little leap of faith, Jimmy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Your logic runs out\\nof steam!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Jim,\\n\\nSorry I can't pity you, Jim.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>And I'm sorry that you have these feelings of\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Oh well, just pretend that it will\\nall end ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Maybe if you start a new newsgroup,\\nalt.athei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Bye-Bye, Big Jim.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Don't forget your Flintstone's Chewables!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>:) \\n--\\nBake Timmons, III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Although I realize that principle is not one o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>If you want to continue this think tank charad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>You might have to start asking the\\nsame sort ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>You realize it\\nwould not work, as the Arab co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Everyone in this group recognizes that your st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Notwithstanding all the legitimate fuss about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ATT's last product in this area (a) was priced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Thus,\\naside from attempting to further legiti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128373</th>\n",
              "      <td>11309</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Berkeley campus.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128374</th>\n",
              "      <td>11309</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The talk is\\nsponsored by the Berkeley Israel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128375</th>\n",
              "      <td>11311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>\\nI agree.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128376</th>\n",
              "      <td>11311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Home runs off Clemens are always memorable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128377</th>\n",
              "      <td>11311</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Kinda like\\neclipses and hurricanes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128378</th>\n",
              "      <td>11311</td>\n",
              "      <td>3.0</td>\n",
              "      <td>They don't happen very often.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128379</th>\n",
              "      <td>11312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I used HP DeskJet with Orange Micros Grappler ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128380</th>\n",
              "      <td>11312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>But now I update system 6.0.5 to System7 with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128381</th>\n",
              "      <td>11312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Is the Grappler LS old ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128382</th>\n",
              "      <td>11312</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Can I use DeskJet on System7 ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128383</th>\n",
              "      <td>11312</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Please tell me how to use DeskJet on System7.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128384</th>\n",
              "      <td>11312</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Thank you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128385</th>\n",
              "      <td>11313</td>\n",
              "      <td>0.0</td>\n",
              "      <td>^^^^^^\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128386</th>\n",
              "      <td>11313</td>\n",
              "      <td>1.0</td>\n",
              "      <td>He scared the hell out of me when he came in\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128387</th>\n",
              "      <td>11313</td>\n",
              "      <td>2.0</td>\n",
              "      <td>On the other hand, the club though enough of B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128388</th>\n",
              "      <td>11313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>He seemed to be a very viable setup guy - but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128389</th>\n",
              "      <td>11313</td>\n",
              "      <td>4.0</td>\n",
              "      <td>I can just remember two years\\nago so well, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128390</th>\n",
              "      <td>11313</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I'm not that concerned.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128391</th>\n",
              "      <td>11313</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Those guys have been relatively consistent ove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128392</th>\n",
              "      <td>11313</td>\n",
              "      <td>7.0</td>\n",
              "      <td>I expect them to come through just fine.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128393</th>\n",
              "      <td>11313</td>\n",
              "      <td>8.0</td>\n",
              "      <td>It's those guys that have not\\nbeen consistent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128394</th>\n",
              "      <td>11313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>This sounds like their old road unis.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128395</th>\n",
              "      <td>11313</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Pretty dull.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128396</th>\n",
              "      <td>11313</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Buttons or pullovers?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128397</th>\n",
              "      <td>11313</td>\n",
              "      <td>12.0</td>\n",
              "      <td>I'll check through my uniform book to see if t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128398</th>\n",
              "      <td>11313</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Well, we'll see.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128399</th>\n",
              "      <td>11313</td>\n",
              "      <td>14.0</td>\n",
              "      <td>I've got a Astros pullover shirt with the \"Ast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128400</th>\n",
              "      <td>11313</td>\n",
              "      <td>15.0</td>\n",
              "      <td>i\\ncan see why they might want that to change.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128401</th>\n",
              "      <td>11313</td>\n",
              "      <td>16.0</td>\n",
              "      <td>Gee, if they eliminate the\\norange, will they ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128402</th>\n",
              "      <td>11313</td>\n",
              "      <td>17.0</td>\n",
              "      <td>I saw a pinstripe version of an Astros cap and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128403 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index_P  index_sent                                           sentence\n",
              "0            0         0.0  Well i'm not sure about the story nad it did s...\n",
              "1            0         1.0  What\\nI disagree with is your statement that t...\n",
              "2            0         2.0                                That is rediculous.\n",
              "3            0         3.0  The U.S. media is\\nthe most pro-israeli media ...\n",
              "4            0         4.0  Having lived in Europe\\nI realize that inciden...\n",
              "5            0         5.0  The U.S. media as a whole seem to try to\\nigno...\n",
              "6            0         6.0  The U.S. is subsidizing Israels existance and ...\n",
              "7            0         7.0  So I think\\nthat might be a reason they report...\n",
              "8            0         8.0  What is a shame is that in Austria, daily repo...\n",
              "9            0         9.0  After all, look how the Jews are treating othe...\n",
              "10           0        10.0                                 It is unfortunate.\n",
              "11           1         0.0  \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to re...\n",
              "12           1         1.0                 and actually accept hard\\natheism?\n",
              "13           1         2.0        No, you need a little leap of faith, Jimmy.\n",
              "14           1         3.0                     Your logic runs out\\nof steam!\n",
              "15           1         4.0               Jim,\\n\\nSorry I can't pity you, Jim.\n",
              "16           1         5.0  And I'm sorry that you have these feelings of\\...\n",
              "17           1         6.0  Oh well, just pretend that it will\\nall end ha...\n",
              "18           1         7.0  Maybe if you start a new newsgroup,\\nalt.athei...\n",
              "19           1         8.0                                  Bye-Bye, Big Jim.\n",
              "20           1         9.0          Don't forget your Flintstone's Chewables!\n",
              "21           1        10.0                         :) \\n--\\nBake Timmons, III\n",
              "22           2         0.0  Although I realize that principle is not one o...\n",
              "23           2         1.0  If you want to continue this think tank charad...\n",
              "24           2         2.0  You might have to start asking the\\nsame sort ...\n",
              "25           2         3.0  You realize it\\nwould not work, as the Arab co...\n",
              "26           2         4.0  Everyone in this group recognizes that your st...\n",
              "27           3         0.0  Notwithstanding all the legitimate fuss about ...\n",
              "28           3         1.0  ATT's last product in this area (a) was priced...\n",
              "29           3         2.0  Thus,\\naside from attempting to further legiti...\n",
              "...        ...         ...                                                ...\n",
              "128373   11309         2.0                                   Berkeley campus.\n",
              "128374   11309         3.0  The talk is\\nsponsored by the Berkeley Israel ...\n",
              "128375   11311         0.0                                         \\nI agree.\n",
              "128376   11311         1.0        Home runs off Clemens are always memorable.\n",
              "128377   11311         2.0               Kinda like\\neclipses and hurricanes.\n",
              "128378   11311         3.0                      They don't happen very often.\n",
              "128379   11312         0.0  I used HP DeskJet with Orange Micros Grappler ...\n",
              "128380   11312         1.0  But now I update system 6.0.5 to System7 with ...\n",
              "128381   11312         2.0                           Is the Grappler LS old ?\n",
              "128382   11312         3.0                     Can I use DeskJet on System7 ?\n",
              "128383   11312         4.0      Please tell me how to use DeskJet on System7.\n",
              "128384   11312         5.0                                          Thank you\n",
              "128385   11313         0.0                                        ^^^^^^\\n...\n",
              "128386   11313         1.0  He scared the hell out of me when he came in\\n...\n",
              "128387   11313         2.0  On the other hand, the club though enough of B...\n",
              "128388   11313         3.0  He seemed to be a very viable setup guy - but ...\n",
              "128389   11313         4.0  I can just remember two years\\nago so well, th...\n",
              "128390   11313         5.0                            I'm not that concerned.\n",
              "128391   11313         6.0  Those guys have been relatively consistent ove...\n",
              "128392   11313         7.0           I expect them to come through just fine.\n",
              "128393   11313         8.0  It's those guys that have not\\nbeen consistent...\n",
              "128394   11313         9.0              This sounds like their old road unis.\n",
              "128395   11313        10.0                                       Pretty dull.\n",
              "128396   11313        11.0                              Buttons or pullovers?\n",
              "128397   11313        12.0  I'll check through my uniform book to see if t...\n",
              "128398   11313        13.0                                   Well, we'll see.\n",
              "128399   11313        14.0  I've got a Astros pullover shirt with the \"Ast...\n",
              "128400   11313        15.0     i\\ncan see why they might want that to change.\n",
              "128401   11313        16.0  Gee, if they eliminate the\\norange, will they ...\n",
              "128402   11313        17.0  I saw a pinstripe version of an Astros cap and...\n",
              "\n",
              "[128403 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "9AecJWi87X8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1992
        },
        "outputId": "b79e23a2-333d-4e5a-9ea5-32b4e69461f0"
      },
      "cell_type": "code",
      "source": [
        "df_Sentences_not_stops=read_cvs_by_pands(path_database,Sentences_not_stops,None,0)\n",
        "df_Sentences_not_stops"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>words_not_stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['Well', \"i'm\", 'sure', 'story', 'nad', 'seem'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['disagree', 'statement', 'U', 'Media', 'ruin'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['rediculous']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['U', 'media', 'pro', 'israeli', 'media', 'wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['lived', 'Europe', 'realize', 'incidences', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>['U', 'subsidizing', 'Israels', 'existance', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>['think', 'might', 'reason', 'report', 'clearl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['look', 'Jews', 'treating', 'races', 'got', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['unfortunate']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['Yeah', 'expect', 'people', 'read', 'FAQ', 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['actually', 'accept', 'hard', 'atheism']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['need', 'little', 'leap', 'faith', 'Jimmy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['logic', 'runs', 'steam']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['Jim', 'Sorry', \"can't\", 'pity', 'Jim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>['Oh', 'well', 'pretend', 'end', 'happily', 'e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>['Bye', 'Bye', 'Big', 'Jim']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['forget', \"Flintstone's\", 'Chewables']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['Bake', 'Timmons', 'III']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['Although', 'realize', 'principle', 'one', 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['want', 'continue', 'think', 'tank', 'charade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['Everyone', 'group', 'recognizes', 'stupid', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[\"ATT's\", 'last', 'product', 'area', 'priced',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['Thus', 'aside', 'attempting', 'legitimize', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128373</th>\n",
              "      <td>11309</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['Berkeley', 'campus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128374</th>\n",
              "      <td>11309</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['talk', 'sponsored', 'Berkeley', 'Israel', 'A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128375</th>\n",
              "      <td>11311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['agree']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128376</th>\n",
              "      <td>11311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['Home', 'runs', 'Clemens', 'always', 'memorab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128377</th>\n",
              "      <td>11311</td>\n",
              "      <td>2.0</td>\n",
              "      <td>['Kinda', 'like', 'eclipses', 'hurricanes']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128378</th>\n",
              "      <td>11311</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128379</th>\n",
              "      <td>11312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['used', 'HP', 'DeskJet', 'Orange', 'Micros', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128380</th>\n",
              "      <td>11312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>['update', 'system', 'System7', 'Kanji', 'Talk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128381</th>\n",
              "      <td>11312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128382</th>\n",
              "      <td>11312</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['use', 'DeskJet', 'System7']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128383</th>\n",
              "      <td>11312</td>\n",
              "      <td>4.0</td>\n",
              "      <td>['Please', 'tell', 'use', 'DeskJet', 'System7']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128384</th>\n",
              "      <td>11312</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128385</th>\n",
              "      <td>11313</td>\n",
              "      <td>0.0</td>\n",
              "      <td>['argument', 'Murphy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128386</th>\n",
              "      <td>11313</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128387</th>\n",
              "      <td>11313</td>\n",
              "      <td>2.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128388</th>\n",
              "      <td>11313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>['seemed', 'viable', 'setup', 'guy', 'guess', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128389</th>\n",
              "      <td>11313</td>\n",
              "      <td>4.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128390</th>\n",
              "      <td>11313</td>\n",
              "      <td>5.0</td>\n",
              "      <td>[\"I'm\", 'concerned']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128391</th>\n",
              "      <td>11313</td>\n",
              "      <td>6.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128392</th>\n",
              "      <td>11313</td>\n",
              "      <td>7.0</td>\n",
              "      <td>['expect', 'come', 'fine']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128393</th>\n",
              "      <td>11313</td>\n",
              "      <td>8.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128394</th>\n",
              "      <td>11313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['sounds', 'like', 'old', 'road', 'unis']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128395</th>\n",
              "      <td>11313</td>\n",
              "      <td>10.0</td>\n",
              "      <td>['Pretty', 'dull']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128396</th>\n",
              "      <td>11313</td>\n",
              "      <td>11.0</td>\n",
              "      <td>['Buttons', 'pullovers']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128397</th>\n",
              "      <td>11313</td>\n",
              "      <td>12.0</td>\n",
              "      <td>[\"I'll\", 'check', 'uniform', 'book', 'see', \"t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128398</th>\n",
              "      <td>11313</td>\n",
              "      <td>13.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128399</th>\n",
              "      <td>11313</td>\n",
              "      <td>14.0</td>\n",
              "      <td>[\"I've\", 'got', 'Astros', 'pullover', 'shirt',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128400</th>\n",
              "      <td>11313</td>\n",
              "      <td>15.0</td>\n",
              "      <td>['see', 'might', 'want', 'change']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128401</th>\n",
              "      <td>11313</td>\n",
              "      <td>16.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128402</th>\n",
              "      <td>11313</td>\n",
              "      <td>17.0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128403 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index_P  index_sent                                     words_not_stop\n",
              "0            0         0.0  ['Well', \"i'm\", 'sure', 'story', 'nad', 'seem'...\n",
              "1            0         1.0  ['disagree', 'statement', 'U', 'Media', 'ruin'...\n",
              "2            0         2.0                                     ['rediculous']\n",
              "3            0         3.0  ['U', 'media', 'pro', 'israeli', 'media', 'wor...\n",
              "4            0         4.0  ['lived', 'Europe', 'realize', 'incidences', '...\n",
              "5            0         5.0                                                 []\n",
              "6            0         6.0  ['U', 'subsidizing', 'Israels', 'existance', '...\n",
              "7            0         7.0  ['think', 'might', 'reason', 'report', 'clearl...\n",
              "8            0         8.0                                                 []\n",
              "9            0         9.0  ['look', 'Jews', 'treating', 'races', 'got', '...\n",
              "10           0        10.0                                    ['unfortunate']\n",
              "11           1         0.0  ['Yeah', 'expect', 'people', 'read', 'FAQ', 'e...\n",
              "12           1         1.0          ['actually', 'accept', 'hard', 'atheism']\n",
              "13           1         2.0       ['need', 'little', 'leap', 'faith', 'Jimmy']\n",
              "14           1         3.0                         ['logic', 'runs', 'steam']\n",
              "15           1         4.0           ['Jim', 'Sorry', \"can't\", 'pity', 'Jim']\n",
              "16           1         5.0                                                 []\n",
              "17           1         6.0  ['Oh', 'well', 'pretend', 'end', 'happily', 'e...\n",
              "18           1         7.0                                                 []\n",
              "19           1         8.0                       ['Bye', 'Bye', 'Big', 'Jim']\n",
              "20           1         9.0            ['forget', \"Flintstone's\", 'Chewables']\n",
              "21           1        10.0                         ['Bake', 'Timmons', 'III']\n",
              "22           2         0.0  ['Although', 'realize', 'principle', 'one', 's...\n",
              "23           2         1.0  ['want', 'continue', 'think', 'tank', 'charade...\n",
              "24           2         2.0                                                 []\n",
              "25           2         3.0                                                 []\n",
              "26           2         4.0  ['Everyone', 'group', 'recognizes', 'stupid', ...\n",
              "27           3         0.0                                                 []\n",
              "28           3         1.0  [\"ATT's\", 'last', 'product', 'area', 'priced',...\n",
              "29           3         2.0  ['Thus', 'aside', 'attempting', 'legitimize', ...\n",
              "...        ...         ...                                                ...\n",
              "128373   11309         2.0                             ['Berkeley', 'campus']\n",
              "128374   11309         3.0  ['talk', 'sponsored', 'Berkeley', 'Israel', 'A...\n",
              "128375   11311         0.0                                          ['agree']\n",
              "128376   11311         1.0  ['Home', 'runs', 'Clemens', 'always', 'memorab...\n",
              "128377   11311         2.0        ['Kinda', 'like', 'eclipses', 'hurricanes']\n",
              "128378   11311         3.0                                                 []\n",
              "128379   11312         0.0  ['used', 'HP', 'DeskJet', 'Orange', 'Micros', ...\n",
              "128380   11312         1.0  ['update', 'system', 'System7', 'Kanji', 'Talk...\n",
              "128381   11312         2.0                                                 []\n",
              "128382   11312         3.0                      ['use', 'DeskJet', 'System7']\n",
              "128383   11312         4.0    ['Please', 'tell', 'use', 'DeskJet', 'System7']\n",
              "128384   11312         5.0                                                 []\n",
              "128385   11313         0.0                             ['argument', 'Murphy']\n",
              "128386   11313         1.0                                                 []\n",
              "128387   11313         2.0                                                 []\n",
              "128388   11313         3.0  ['seemed', 'viable', 'setup', 'guy', 'guess', ...\n",
              "128389   11313         4.0                                                 []\n",
              "128390   11313         5.0                               [\"I'm\", 'concerned']\n",
              "128391   11313         6.0                                                 []\n",
              "128392   11313         7.0                         ['expect', 'come', 'fine']\n",
              "128393   11313         8.0                                                 []\n",
              "128394   11313         9.0          ['sounds', 'like', 'old', 'road', 'unis']\n",
              "128395   11313        10.0                                 ['Pretty', 'dull']\n",
              "128396   11313        11.0                           ['Buttons', 'pullovers']\n",
              "128397   11313        12.0  [\"I'll\", 'check', 'uniform', 'book', 'see', \"t...\n",
              "128398   11313        13.0                                                 []\n",
              "128399   11313        14.0  [\"I've\", 'got', 'Astros', 'pullover', 'shirt',...\n",
              "128400   11313        15.0                 ['see', 'might', 'want', 'change']\n",
              "128401   11313        16.0                                                 []\n",
              "128402   11313        17.0                                                 []\n",
              "\n",
              "[128403 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "lTjZb-JWzFp8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "75LvkDP6CONE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "this function for compute lesk of word in sentence\n",
        "'''\n",
        "def lesk_word_sentence(sentence,words):\n",
        "    from nltk.wsd import lesk\n",
        "    lesk_synset=''\n",
        "    \n",
        "    lesks_row= []\n",
        "    lesks_name=[]\n",
        "    #print(type(words))\n",
        "    for i in range(len(words)):\n",
        "        \n",
        "        disambiguated=lesk(context_sentence=str(sentence), ambiguous_word=words[i].strip())\n",
        "        \n",
        "        \n",
        "        if disambiguated is not None:\n",
        "            lesks_row.append(disambiguated)\n",
        "            lesks_name.append(disambiguated.name())\n",
        "    \n",
        "    \n",
        "    return lesks_row,lesks_name\n",
        "#disambiguated#lesk_synset\n",
        "\n",
        "#lesk(\"Computer science is a discipline that spans theory and practice\",\"science\")\n",
        "\n",
        "#sent = 'people should be able to marry a person of their choice'.split()\n",
        "#ll=['Well','\"im\"','sure','story','nad','seem','biased']\n",
        "#lesk_word_sentence(\"Well i'm not sure about the story nad it did seem biased.\", ll)\n",
        "#lesk('I love dog', 'dog')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LeAahyGoPe1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2444
        },
        "outputId": "43c473ac-5af0-4345-f2ce-47848e88fa8b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def sent_lesks():\n",
        "    df_Sentences=read_cvs_by_pands(path_database,Sentences,None,0)\n",
        "    #print(df_Sentences.columns)\n",
        "    df_Sentences_not_stops=read_cvs_by_pands(path_database,Sentences_not_stops,None,0)\n",
        "    lesks=[]\n",
        "    for i in range(len(df_Sentences_not_stops)):\n",
        "        sent=[]\n",
        "        full_words=df_Sentences_not_stops['words_not_stop'][i].replace(\"[\",'').replace(\"]\",'').replace(\"'\",'').replace('\"','')\n",
        "        full_words_list=full_words.replace(\",\",'-')      \n",
        "        words=full_words.split(',')\n",
        "        sentense=df_Sentences['sentence'][i]\n",
        "        \n",
        "        sent.append(df_Sentences['index_P'][i])\n",
        "        sent.append(df_Sentences['index_sent'][i])\n",
        "        ss=lesk_word_sentence(sentense, words)\n",
        "        \n",
        "        sent.append(full_words_list)\n",
        "        sent.append(ss[0])\n",
        "        sent.append(ss[1])\n",
        "        \n",
        "        lesks.append(sent)\n",
        "        \n",
        "    header_list=['index_P','index_sent','full_word','lesks','lesks_name']\n",
        "    df = pd.DataFrame(lesks, columns=header_list)\n",
        "    \n",
        "    df.to_csv(path_database+'lesk_20.csv', encoding='utf-8', index=False)  \n",
        "    return df\n",
        "    #return lesks\n",
        "sent_lesks()\n",
        "    "
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>full_word</th>\n",
              "      <th>lesks</th>\n",
              "      <th>lesks_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Well- im- sure- story- nad- seem- biased</td>\n",
              "      <td>[Synset('well.v.01'), Synset('surely.r.01'), S...</td>\n",
              "      <td>[well.v.01, surely.r.01, story.n.02, nicotinam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>disagree- statement- U- Media- ruin- Israels- ...</td>\n",
              "      <td>[Synset('disagree.v.02'), Synset('statement.n....</td>\n",
              "      <td>[disagree.v.02, statement.n.07, uranium.n.01, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>rediculous</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>U- media- pro- israeli- media- world</td>\n",
              "      <td>[Synset('uranium.n.01'), Synset('medium.n.08')...</td>\n",
              "      <td>[uranium.n.01, medium.n.08, pro.r.01, israeli....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lived- Europe- realize- incidences- one- descr...</td>\n",
              "      <td>[Synset('live.v.07'), Synset('europe.n.01'), S...</td>\n",
              "      <td>[live.v.07, europe.n.01, realize.v.06, inciden...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>U- subsidizing- Israels- existance- Europeans-...</td>\n",
              "      <td>[Synset('uranium.n.01'), Synset('subsidize.v.0...</td>\n",
              "      <td>[uranium.n.01, subsidize.v.02, israel.n.02, eu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>think- might- reason- report- clearly- atrocities</td>\n",
              "      <td>[Synset('think.v.13'), Synset('might.n.01'), S...</td>\n",
              "      <td>[think.v.13, might.n.01, reason.v.01, reputati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>look- Jews- treating- races- got- power</td>\n",
              "      <td>[Synset('spirit.n.02'), Synset('jew.n.01'), Sy...</td>\n",
              "      <td>[spirit.n.02, jew.n.01, treat.v.08, subspecies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>unfortunate</td>\n",
              "      <td>[Synset('unfortunate.n.01')]</td>\n",
              "      <td>[unfortunate.n.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yeah- expect- people- read- FAQ- etc</td>\n",
              "      <td>[Synset('yea.r.01'), Synset('expect.v.05'), Sy...</td>\n",
              "      <td>[yea.r.01, expect.v.05, people.n.03, understan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>actually- accept- hard- atheism</td>\n",
              "      <td>[Synset('actually.r.04'), Synset('accept.v.11'...</td>\n",
              "      <td>[actually.r.04, accept.v.11, hard.s.10, atheis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>need- little- leap- faith- Jimmy</td>\n",
              "      <td>[Synset('need.v.03'), Synset('little.s.08'), S...</td>\n",
              "      <td>[need.v.03, little.s.08, leap.n.01, religion.n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>logic- runs- steam</td>\n",
              "      <td>[Synset('logic.n.05'), Synset('tend.v.01'), Sy...</td>\n",
              "      <td>[logic.n.05, tend.v.01, steamer.v.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Jim- Sorry- cant- pity- Jim</td>\n",
              "      <td>[Synset('regretful.a.01'), Synset('slang.n.02'...</td>\n",
              "      <td>[regretful.a.01, slang.n.02, commiseration.n.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Oh- well- pretend- end- happily- ever- anyway</td>\n",
              "      <td>[Synset('ohio.n.01'), Synset('well.v.01'), Syn...</td>\n",
              "      <td>[ohio.n.01, well.v.01, pretend.v.03, goal.n.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Bye- Bye- Big- Jim</td>\n",
              "      <td>[Synset('bye.n.01'), Synset('bye.n.01'), Synse...</td>\n",
              "      <td>[bye.n.01, bye.n.01, large.a.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>forget- Flintstones- Chewables</td>\n",
              "      <td>[Synset('forget.v.04'), Synset('flintstone.n.0...</td>\n",
              "      <td>[forget.v.04, flintstone.n.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Bake- Timmons- III</td>\n",
              "      <td>[Synset('broil.v.02'), Synset('three.s.01')]</td>\n",
              "      <td>[broil.v.02, three.s.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Although- realize- principle- one- strongest- ...</td>\n",
              "      <td>[Synset('realize.v.06'), Synset('principle.n.0...</td>\n",
              "      <td>[realize.v.06, principle.n.04, one.s.06, poten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>want- continue- think- tank- charade- fixation...</td>\n",
              "      <td>[Synset('wish.n.01'), Synset('stay.v.04'), Syn...</td>\n",
              "      <td>[wish.n.01, stay.v.04, think.v.13, tank_car.n....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Everyone- group- recognizes- stupid- Center- P...</td>\n",
              "      <td>[Synset('group.v.02'), Synset('recognize.v.08'...</td>\n",
              "      <td>[group.v.02, recognize.v.08, stupid.n.01, plaz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ATTs- last- product- area- priced- suspect- cl...</td>\n",
              "      <td>[Synset('last.v.01'), Synset('product.n.05'), ...</td>\n",
              "      <td>[last.v.01, product.n.05, sphere.n.01, price.v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Thus- aside- attempting- legitimize- solidify-...</td>\n",
              "      <td>[Synset('thus.r.02'), Synset('digression.n.01'...</td>\n",
              "      <td>[thus.r.02, digression.n.01, undertake.v.01, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128373</th>\n",
              "      <td>11309</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Berkeley- campus</td>\n",
              "      <td>[Synset('berkeley.n.02'), Synset('campus.n.01')]</td>\n",
              "      <td>[berkeley.n.02, campus.n.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128374</th>\n",
              "      <td>11309</td>\n",
              "      <td>3.0</td>\n",
              "      <td>talk- sponsored- Berkeley- Israel- Action- Com...</td>\n",
              "      <td>[Synset('talk.n.03'), Synset('patronize.v.02')...</td>\n",
              "      <td>[talk.n.03, patronize.v.02, berkeley.n.02, isr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128375</th>\n",
              "      <td>11311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>agree</td>\n",
              "      <td>[Synset('agree.v.02')]</td>\n",
              "      <td>[agree.v.02]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128376</th>\n",
              "      <td>11311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Home- runs- Clemens- always- memorable</td>\n",
              "      <td>[Synset('home_plate.n.01'), Synset('tend.v.01'...</td>\n",
              "      <td>[home_plate.n.01, tend.v.01, clemens.n.01, con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128377</th>\n",
              "      <td>11311</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Kinda- like- eclipses- hurricanes</td>\n",
              "      <td>[Synset('rather.r.02'), Synset('like.n.02'), S...</td>\n",
              "      <td>[rather.r.02, like.n.02, overshadow.v.01, hurr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128378</th>\n",
              "      <td>11311</td>\n",
              "      <td>3.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128379</th>\n",
              "      <td>11312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>used- HP- DeskJet- Orange- Micros- Grappler- L...</td>\n",
              "      <td>[Synset('use.v.01'), Synset('horsepower.n.01')...</td>\n",
              "      <td>[use.v.01, horsepower.n.01, orange.s.01, grapn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128380</th>\n",
              "      <td>11312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>update- system- System7- Kanji- Talk- print- D...</td>\n",
              "      <td>[Synset('update.v.03'), Synset('system.n.08'),...</td>\n",
              "      <td>[update.v.03, system.n.08, talk.n.03, print.v.03]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128381</th>\n",
              "      <td>11312</td>\n",
              "      <td>2.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128382</th>\n",
              "      <td>11312</td>\n",
              "      <td>3.0</td>\n",
              "      <td>use- DeskJet- System7</td>\n",
              "      <td>[Synset('use.v.01')]</td>\n",
              "      <td>[use.v.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128383</th>\n",
              "      <td>11312</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Please- tell- use- DeskJet- System7</td>\n",
              "      <td>[Synset('please.v.03'), Synset('tell.v.03'), S...</td>\n",
              "      <td>[please.v.03, tell.v.03, use.v.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128384</th>\n",
              "      <td>11312</td>\n",
              "      <td>5.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128385</th>\n",
              "      <td>11313</td>\n",
              "      <td>0.0</td>\n",
              "      <td>argument- Murphy</td>\n",
              "      <td>[Synset('controversy.n.01'), Synset('potato.n....</td>\n",
              "      <td>[controversy.n.01, potato.n.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128386</th>\n",
              "      <td>11313</td>\n",
              "      <td>1.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128387</th>\n",
              "      <td>11313</td>\n",
              "      <td>2.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128388</th>\n",
              "      <td>11313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>seemed- viable- setup- guy- guess- thats- cons...</td>\n",
              "      <td>[Synset('look.v.02'), Synset('viable.s.02'), S...</td>\n",
              "      <td>[look.v.02, viable.s.02, frame-up.n.01, guy.v....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128389</th>\n",
              "      <td>11313</td>\n",
              "      <td>4.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128390</th>\n",
              "      <td>11313</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Im- concerned</td>\n",
              "      <td>[Synset('concerned.s.02')]</td>\n",
              "      <td>[concerned.s.02]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128391</th>\n",
              "      <td>11313</td>\n",
              "      <td>6.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128392</th>\n",
              "      <td>11313</td>\n",
              "      <td>7.0</td>\n",
              "      <td>expect- come- fine</td>\n",
              "      <td>[Synset('have_a_bun_in_the_oven.v.01'), Synset...</td>\n",
              "      <td>[have_a_bun_in_the_oven.v.01, total.v.01, very...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128393</th>\n",
              "      <td>11313</td>\n",
              "      <td>8.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128394</th>\n",
              "      <td>11313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>sounds- like- old- road- unis</td>\n",
              "      <td>[Synset('strait.n.01'), Synset('like.n.02'), S...</td>\n",
              "      <td>[strait.n.01, like.n.02, old.s.07, road.n.02]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128395</th>\n",
              "      <td>11313</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Pretty- dull</td>\n",
              "      <td>[Synset('reasonably.r.01'), Synset('pall.v.01')]</td>\n",
              "      <td>[reasonably.r.01, pall.v.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128396</th>\n",
              "      <td>11313</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Buttons- pullovers</td>\n",
              "      <td>[Synset('release.n.08'), Synset('pullover.n.01')]</td>\n",
              "      <td>[release.n.08, pullover.n.01]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128397</th>\n",
              "      <td>11313</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Ill- check- uniform- book- see- theyve- always...</td>\n",
              "      <td>[Synset('ill.r.01'), Synset('check_mark.n.01')...</td>\n",
              "      <td>[ill.r.01, check_mark.n.01, uniform.n.01, scri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128398</th>\n",
              "      <td>11313</td>\n",
              "      <td>13.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128399</th>\n",
              "      <td>11313</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Ive- got- Astros- pullover- shirt- Astros- str...</td>\n",
              "      <td>[Synset('receive.v.02'), Synset('pullover.n.01...</td>\n",
              "      <td>[receive.v.02, pullover.n.01, shirt.v.01, stri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128400</th>\n",
              "      <td>11313</td>\n",
              "      <td>15.0</td>\n",
              "      <td>see- might- want- change</td>\n",
              "      <td>[Synset('visit.v.01'), Synset('might.n.01'), S...</td>\n",
              "      <td>[visit.v.01, might.n.01, wish.n.01, variety.n.06]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128401</th>\n",
              "      <td>11313</td>\n",
              "      <td>16.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128402</th>\n",
              "      <td>11313</td>\n",
              "      <td>17.0</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128403 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index_P  index_sent                                          full_word  \\\n",
              "0            0         0.0           Well- im- sure- story- nad- seem- biased   \n",
              "1            0         1.0  disagree- statement- U- Media- ruin- Israels- ...   \n",
              "2            0         2.0                                         rediculous   \n",
              "3            0         3.0               U- media- pro- israeli- media- world   \n",
              "4            0         4.0  lived- Europe- realize- incidences- one- descr...   \n",
              "5            0         5.0                                                      \n",
              "6            0         6.0  U- subsidizing- Israels- existance- Europeans-...   \n",
              "7            0         7.0  think- might- reason- report- clearly- atrocities   \n",
              "8            0         8.0                                                      \n",
              "9            0         9.0            look- Jews- treating- races- got- power   \n",
              "10           0        10.0                                        unfortunate   \n",
              "11           1         0.0               Yeah- expect- people- read- FAQ- etc   \n",
              "12           1         1.0                    actually- accept- hard- atheism   \n",
              "13           1         2.0                   need- little- leap- faith- Jimmy   \n",
              "14           1         3.0                                 logic- runs- steam   \n",
              "15           1         4.0                        Jim- Sorry- cant- pity- Jim   \n",
              "16           1         5.0                                                      \n",
              "17           1         6.0      Oh- well- pretend- end- happily- ever- anyway   \n",
              "18           1         7.0                                                      \n",
              "19           1         8.0                                 Bye- Bye- Big- Jim   \n",
              "20           1         9.0                     forget- Flintstones- Chewables   \n",
              "21           1        10.0                                 Bake- Timmons- III   \n",
              "22           2         0.0  Although- realize- principle- one- strongest- ...   \n",
              "23           2         1.0  want- continue- think- tank- charade- fixation...   \n",
              "24           2         2.0                                                      \n",
              "25           2         3.0                                                      \n",
              "26           2         4.0  Everyone- group- recognizes- stupid- Center- P...   \n",
              "27           3         0.0                                                      \n",
              "28           3         1.0  ATTs- last- product- area- priced- suspect- cl...   \n",
              "29           3         2.0  Thus- aside- attempting- legitimize- solidify-...   \n",
              "...        ...         ...                                                ...   \n",
              "128373   11309         2.0                                   Berkeley- campus   \n",
              "128374   11309         3.0  talk- sponsored- Berkeley- Israel- Action- Com...   \n",
              "128375   11311         0.0                                              agree   \n",
              "128376   11311         1.0             Home- runs- Clemens- always- memorable   \n",
              "128377   11311         2.0                  Kinda- like- eclipses- hurricanes   \n",
              "128378   11311         3.0                                                      \n",
              "128379   11312         0.0  used- HP- DeskJet- Orange- Micros- Grappler- L...   \n",
              "128380   11312         1.0  update- system- System7- Kanji- Talk- print- D...   \n",
              "128381   11312         2.0                                                      \n",
              "128382   11312         3.0                              use- DeskJet- System7   \n",
              "128383   11312         4.0                Please- tell- use- DeskJet- System7   \n",
              "128384   11312         5.0                                                      \n",
              "128385   11313         0.0                                   argument- Murphy   \n",
              "128386   11313         1.0                                                      \n",
              "128387   11313         2.0                                                      \n",
              "128388   11313         3.0  seemed- viable- setup- guy- guess- thats- cons...   \n",
              "128389   11313         4.0                                                      \n",
              "128390   11313         5.0                                      Im- concerned   \n",
              "128391   11313         6.0                                                      \n",
              "128392   11313         7.0                                 expect- come- fine   \n",
              "128393   11313         8.0                                                      \n",
              "128394   11313         9.0                      sounds- like- old- road- unis   \n",
              "128395   11313        10.0                                       Pretty- dull   \n",
              "128396   11313        11.0                                 Buttons- pullovers   \n",
              "128397   11313        12.0  Ill- check- uniform- book- see- theyve- always...   \n",
              "128398   11313        13.0                                                      \n",
              "128399   11313        14.0  Ive- got- Astros- pullover- shirt- Astros- str...   \n",
              "128400   11313        15.0                           see- might- want- change   \n",
              "128401   11313        16.0                                                      \n",
              "128402   11313        17.0                                                      \n",
              "\n",
              "                                                    lesks  \\\n",
              "0       [Synset('well.v.01'), Synset('surely.r.01'), S...   \n",
              "1       [Synset('disagree.v.02'), Synset('statement.n....   \n",
              "2                                                      []   \n",
              "3       [Synset('uranium.n.01'), Synset('medium.n.08')...   \n",
              "4       [Synset('live.v.07'), Synset('europe.n.01'), S...   \n",
              "5                                                      []   \n",
              "6       [Synset('uranium.n.01'), Synset('subsidize.v.0...   \n",
              "7       [Synset('think.v.13'), Synset('might.n.01'), S...   \n",
              "8                                                      []   \n",
              "9       [Synset('spirit.n.02'), Synset('jew.n.01'), Sy...   \n",
              "10                           [Synset('unfortunate.n.01')]   \n",
              "11      [Synset('yea.r.01'), Synset('expect.v.05'), Sy...   \n",
              "12      [Synset('actually.r.04'), Synset('accept.v.11'...   \n",
              "13      [Synset('need.v.03'), Synset('little.s.08'), S...   \n",
              "14      [Synset('logic.n.05'), Synset('tend.v.01'), Sy...   \n",
              "15      [Synset('regretful.a.01'), Synset('slang.n.02'...   \n",
              "16                                                     []   \n",
              "17      [Synset('ohio.n.01'), Synset('well.v.01'), Syn...   \n",
              "18                                                     []   \n",
              "19      [Synset('bye.n.01'), Synset('bye.n.01'), Synse...   \n",
              "20      [Synset('forget.v.04'), Synset('flintstone.n.0...   \n",
              "21           [Synset('broil.v.02'), Synset('three.s.01')]   \n",
              "22      [Synset('realize.v.06'), Synset('principle.n.0...   \n",
              "23      [Synset('wish.n.01'), Synset('stay.v.04'), Syn...   \n",
              "24                                                     []   \n",
              "25                                                     []   \n",
              "26      [Synset('group.v.02'), Synset('recognize.v.08'...   \n",
              "27                                                     []   \n",
              "28      [Synset('last.v.01'), Synset('product.n.05'), ...   \n",
              "29      [Synset('thus.r.02'), Synset('digression.n.01'...   \n",
              "...                                                   ...   \n",
              "128373   [Synset('berkeley.n.02'), Synset('campus.n.01')]   \n",
              "128374  [Synset('talk.n.03'), Synset('patronize.v.02')...   \n",
              "128375                             [Synset('agree.v.02')]   \n",
              "128376  [Synset('home_plate.n.01'), Synset('tend.v.01'...   \n",
              "128377  [Synset('rather.r.02'), Synset('like.n.02'), S...   \n",
              "128378                                                 []   \n",
              "128379  [Synset('use.v.01'), Synset('horsepower.n.01')...   \n",
              "128380  [Synset('update.v.03'), Synset('system.n.08'),...   \n",
              "128381                                                 []   \n",
              "128382                               [Synset('use.v.01')]   \n",
              "128383  [Synset('please.v.03'), Synset('tell.v.03'), S...   \n",
              "128384                                                 []   \n",
              "128385  [Synset('controversy.n.01'), Synset('potato.n....   \n",
              "128386                                                 []   \n",
              "128387                                                 []   \n",
              "128388  [Synset('look.v.02'), Synset('viable.s.02'), S...   \n",
              "128389                                                 []   \n",
              "128390                         [Synset('concerned.s.02')]   \n",
              "128391                                                 []   \n",
              "128392  [Synset('have_a_bun_in_the_oven.v.01'), Synset...   \n",
              "128393                                                 []   \n",
              "128394  [Synset('strait.n.01'), Synset('like.n.02'), S...   \n",
              "128395   [Synset('reasonably.r.01'), Synset('pall.v.01')]   \n",
              "128396  [Synset('release.n.08'), Synset('pullover.n.01')]   \n",
              "128397  [Synset('ill.r.01'), Synset('check_mark.n.01')...   \n",
              "128398                                                 []   \n",
              "128399  [Synset('receive.v.02'), Synset('pullover.n.01...   \n",
              "128400  [Synset('visit.v.01'), Synset('might.n.01'), S...   \n",
              "128401                                                 []   \n",
              "128402                                                 []   \n",
              "\n",
              "                                               lesks_name  \n",
              "0       [well.v.01, surely.r.01, story.n.02, nicotinam...  \n",
              "1       [disagree.v.02, statement.n.07, uranium.n.01, ...  \n",
              "2                                                      []  \n",
              "3       [uranium.n.01, medium.n.08, pro.r.01, israeli....  \n",
              "4       [live.v.07, europe.n.01, realize.v.06, inciden...  \n",
              "5                                                      []  \n",
              "6       [uranium.n.01, subsidize.v.02, israel.n.02, eu...  \n",
              "7       [think.v.13, might.n.01, reason.v.01, reputati...  \n",
              "8                                                      []  \n",
              "9       [spirit.n.02, jew.n.01, treat.v.08, subspecies...  \n",
              "10                                     [unfortunate.n.01]  \n",
              "11      [yea.r.01, expect.v.05, people.n.03, understan...  \n",
              "12      [actually.r.04, accept.v.11, hard.s.10, atheis...  \n",
              "13      [need.v.03, little.s.08, leap.n.01, religion.n...  \n",
              "14                  [logic.n.05, tend.v.01, steamer.v.01]  \n",
              "15       [regretful.a.01, slang.n.02, commiseration.n.01]  \n",
              "16                                                     []  \n",
              "17      [ohio.n.01, well.v.01, pretend.v.03, goal.n.01...  \n",
              "18                                                     []  \n",
              "19                       [bye.n.01, bye.n.01, large.a.01]  \n",
              "20                         [forget.v.04, flintstone.n.01]  \n",
              "21                               [broil.v.02, three.s.01]  \n",
              "22      [realize.v.06, principle.n.04, one.s.06, poten...  \n",
              "23      [wish.n.01, stay.v.04, think.v.13, tank_car.n....  \n",
              "24                                                     []  \n",
              "25                                                     []  \n",
              "26      [group.v.02, recognize.v.08, stupid.n.01, plaz...  \n",
              "27                                                     []  \n",
              "28      [last.v.01, product.n.05, sphere.n.01, price.v...  \n",
              "29      [thus.r.02, digression.n.01, undertake.v.01, l...  \n",
              "...                                                   ...  \n",
              "128373                       [berkeley.n.02, campus.n.01]  \n",
              "128374  [talk.n.03, patronize.v.02, berkeley.n.02, isr...  \n",
              "128375                                       [agree.v.02]  \n",
              "128376  [home_plate.n.01, tend.v.01, clemens.n.01, con...  \n",
              "128377  [rather.r.02, like.n.02, overshadow.v.01, hurr...  \n",
              "128378                                                 []  \n",
              "128379  [use.v.01, horsepower.n.01, orange.s.01, grapn...  \n",
              "128380  [update.v.03, system.n.08, talk.n.03, print.v.03]  \n",
              "128381                                                 []  \n",
              "128382                                         [use.v.01]  \n",
              "128383                 [please.v.03, tell.v.03, use.v.01]  \n",
              "128384                                                 []  \n",
              "128385                    [controversy.n.01, potato.n.01]  \n",
              "128386                                                 []  \n",
              "128387                                                 []  \n",
              "128388  [look.v.02, viable.s.02, frame-up.n.01, guy.v....  \n",
              "128389                                                 []  \n",
              "128390                                   [concerned.s.02]  \n",
              "128391                                                 []  \n",
              "128392  [have_a_bun_in_the_oven.v.01, total.v.01, very...  \n",
              "128393                                                 []  \n",
              "128394      [strait.n.01, like.n.02, old.s.07, road.n.02]  \n",
              "128395                       [reasonably.r.01, pall.v.01]  \n",
              "128396                      [release.n.08, pullover.n.01]  \n",
              "128397  [ill.r.01, check_mark.n.01, uniform.n.01, scri...  \n",
              "128398                                                 []  \n",
              "128399  [receive.v.02, pullover.n.01, shirt.v.01, stri...  \n",
              "128400  [visit.v.01, might.n.01, wish.n.01, variety.n.06]  \n",
              "128401                                                 []  \n",
              "128402                                                 []  \n",
              "\n",
              "[128403 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "metadata": {
        "id": "RIfVEgdaCcsC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zRzbslo-Cv0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2392
        },
        "outputId": "4e6da057-70b1-4a91-eb54-b3b070a35474"
      },
      "cell_type": "code",
      "source": [
        "l=read_cvs_by_pands(path_database,'lesk_20.csv',None,0)\n",
        "l"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index_P</th>\n",
              "      <th>index_sent</th>\n",
              "      <th>full_word</th>\n",
              "      <th>lesks</th>\n",
              "      <th>lesks_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Well- im- sure- story- nad- seem- biased</td>\n",
              "      <td>[Synset('well.v.01'), Synset('surely.r.01'), S...</td>\n",
              "      <td>['well.v.01', 'surely.r.01', 'story.n.02', 'ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>disagree- statement- U- Media- ruin- Israels- ...</td>\n",
              "      <td>[Synset('disagree.v.02'), Synset('statement.n....</td>\n",
              "      <td>['disagree.v.02', 'statement.n.07', 'uranium.n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>rediculous</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>U- media- pro- israeli- media- world</td>\n",
              "      <td>[Synset('uranium.n.01'), Synset('medium.n.08')...</td>\n",
              "      <td>['uranium.n.01', 'medium.n.08', 'pro.r.01', 'i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>lived- Europe- realize- incidences- one- descr...</td>\n",
              "      <td>[Synset('live.v.07'), Synset('europe.n.01'), S...</td>\n",
              "      <td>['live.v.07', 'europe.n.01', 'realize.v.06', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>U- subsidizing- Israels- existance- Europeans-...</td>\n",
              "      <td>[Synset('uranium.n.01'), Synset('subsidize.v.0...</td>\n",
              "      <td>['uranium.n.01', 'subsidize.v.02', 'israel.n.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>think- might- reason- report- clearly- atrocities</td>\n",
              "      <td>[Synset('think.v.13'), Synset('might.n.01'), S...</td>\n",
              "      <td>['think.v.13', 'might.n.01', 'reason.v.01', 'r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>look- Jews- treating- races- got- power</td>\n",
              "      <td>[Synset('spirit.n.02'), Synset('jew.n.01'), Sy...</td>\n",
              "      <td>['spirit.n.02', 'jew.n.01', 'treat.v.08', 'sub...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>unfortunate</td>\n",
              "      <td>[Synset('unfortunate.n.01')]</td>\n",
              "      <td>['unfortunate.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Yeah- expect- people- read- FAQ- etc</td>\n",
              "      <td>[Synset('yea.r.01'), Synset('expect.v.05'), Sy...</td>\n",
              "      <td>['yea.r.01', 'expect.v.05', 'people.n.03', 'un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>actually- accept- hard- atheism</td>\n",
              "      <td>[Synset('actually.r.04'), Synset('accept.v.11'...</td>\n",
              "      <td>['actually.r.04', 'accept.v.11', 'hard.s.10', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>need- little- leap- faith- Jimmy</td>\n",
              "      <td>[Synset('need.v.03'), Synset('little.s.08'), S...</td>\n",
              "      <td>['need.v.03', 'little.s.08', 'leap.n.01', 'rel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>logic- runs- steam</td>\n",
              "      <td>[Synset('logic.n.05'), Synset('tend.v.01'), Sy...</td>\n",
              "      <td>['logic.n.05', 'tend.v.01', 'steamer.v.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Jim- Sorry- cant- pity- Jim</td>\n",
              "      <td>[Synset('regretful.a.01'), Synset('slang.n.02'...</td>\n",
              "      <td>['regretful.a.01', 'slang.n.02', 'commiseratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Oh- well- pretend- end- happily- ever- anyway</td>\n",
              "      <td>[Synset('ohio.n.01'), Synset('well.v.01'), Syn...</td>\n",
              "      <td>['ohio.n.01', 'well.v.01', 'pretend.v.03', 'go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Bye- Bye- Big- Jim</td>\n",
              "      <td>[Synset('bye.n.01'), Synset('bye.n.01'), Synse...</td>\n",
              "      <td>['bye.n.01', 'bye.n.01', 'large.a.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>forget- Flintstones- Chewables</td>\n",
              "      <td>[Synset('forget.v.04'), Synset('flintstone.n.0...</td>\n",
              "      <td>['forget.v.04', 'flintstone.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Bake- Timmons- III</td>\n",
              "      <td>[Synset('broil.v.02'), Synset('three.s.01')]</td>\n",
              "      <td>['broil.v.02', 'three.s.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Although- realize- principle- one- strongest- ...</td>\n",
              "      <td>[Synset('realize.v.06'), Synset('principle.n.0...</td>\n",
              "      <td>['realize.v.06', 'principle.n.04', 'one.s.06',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>want- continue- think- tank- charade- fixation...</td>\n",
              "      <td>[Synset('wish.n.01'), Synset('stay.v.04'), Syn...</td>\n",
              "      <td>['wish.n.01', 'stay.v.04', 'think.v.13', 'tank...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Everyone- group- recognizes- stupid- Center- P...</td>\n",
              "      <td>[Synset('group.v.02'), Synset('recognize.v.08'...</td>\n",
              "      <td>['group.v.02', 'recognize.v.08', 'stupid.n.01'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ATTs- last- product- area- priced- suspect- cl...</td>\n",
              "      <td>[Synset('last.v.01'), Synset('product.n.05'), ...</td>\n",
              "      <td>['last.v.01', 'product.n.05', 'sphere.n.01', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Thus- aside- attempting- legitimize- solidify-...</td>\n",
              "      <td>[Synset('thus.r.02'), Synset('digression.n.01'...</td>\n",
              "      <td>['thus.r.02', 'digression.n.01', 'undertake.v....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128373</th>\n",
              "      <td>11309</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Berkeley- campus</td>\n",
              "      <td>[Synset('berkeley.n.02'), Synset('campus.n.01')]</td>\n",
              "      <td>['berkeley.n.02', 'campus.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128374</th>\n",
              "      <td>11309</td>\n",
              "      <td>3.0</td>\n",
              "      <td>talk- sponsored- Berkeley- Israel- Action- Com...</td>\n",
              "      <td>[Synset('talk.n.03'), Synset('patronize.v.02')...</td>\n",
              "      <td>['talk.n.03', 'patronize.v.02', 'berkeley.n.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128375</th>\n",
              "      <td>11311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>agree</td>\n",
              "      <td>[Synset('agree.v.02')]</td>\n",
              "      <td>['agree.v.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128376</th>\n",
              "      <td>11311</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Home- runs- Clemens- always- memorable</td>\n",
              "      <td>[Synset('home_plate.n.01'), Synset('tend.v.01'...</td>\n",
              "      <td>['home_plate.n.01', 'tend.v.01', 'clemens.n.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128377</th>\n",
              "      <td>11311</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Kinda- like- eclipses- hurricanes</td>\n",
              "      <td>[Synset('rather.r.02'), Synset('like.n.02'), S...</td>\n",
              "      <td>['rather.r.02', 'like.n.02', 'overshadow.v.01'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128378</th>\n",
              "      <td>11311</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128379</th>\n",
              "      <td>11312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>used- HP- DeskJet- Orange- Micros- Grappler- L...</td>\n",
              "      <td>[Synset('use.v.01'), Synset('horsepower.n.01')...</td>\n",
              "      <td>['use.v.01', 'horsepower.n.01', 'orange.s.01',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128380</th>\n",
              "      <td>11312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>update- system- System7- Kanji- Talk- print- D...</td>\n",
              "      <td>[Synset('update.v.03'), Synset('system.n.08'),...</td>\n",
              "      <td>['update.v.03', 'system.n.08', 'talk.n.03', 'p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128381</th>\n",
              "      <td>11312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128382</th>\n",
              "      <td>11312</td>\n",
              "      <td>3.0</td>\n",
              "      <td>use- DeskJet- System7</td>\n",
              "      <td>[Synset('use.v.01')]</td>\n",
              "      <td>['use.v.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128383</th>\n",
              "      <td>11312</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Please- tell- use- DeskJet- System7</td>\n",
              "      <td>[Synset('please.v.03'), Synset('tell.v.03'), S...</td>\n",
              "      <td>['please.v.03', 'tell.v.03', 'use.v.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128384</th>\n",
              "      <td>11312</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128385</th>\n",
              "      <td>11313</td>\n",
              "      <td>0.0</td>\n",
              "      <td>argument- Murphy</td>\n",
              "      <td>[Synset('controversy.n.01'), Synset('potato.n....</td>\n",
              "      <td>['controversy.n.01', 'potato.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128386</th>\n",
              "      <td>11313</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128387</th>\n",
              "      <td>11313</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128388</th>\n",
              "      <td>11313</td>\n",
              "      <td>3.0</td>\n",
              "      <td>seemed- viable- setup- guy- guess- thats- cons...</td>\n",
              "      <td>[Synset('look.v.02'), Synset('viable.s.02'), S...</td>\n",
              "      <td>['look.v.02', 'viable.s.02', 'frame-up.n.01', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128389</th>\n",
              "      <td>11313</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128390</th>\n",
              "      <td>11313</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Im- concerned</td>\n",
              "      <td>[Synset('concerned.s.02')]</td>\n",
              "      <td>['concerned.s.02']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128391</th>\n",
              "      <td>11313</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128392</th>\n",
              "      <td>11313</td>\n",
              "      <td>7.0</td>\n",
              "      <td>expect- come- fine</td>\n",
              "      <td>[Synset('have_a_bun_in_the_oven.v.01'), Synset...</td>\n",
              "      <td>['have_a_bun_in_the_oven.v.01', 'total.v.01', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128393</th>\n",
              "      <td>11313</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128394</th>\n",
              "      <td>11313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>sounds- like- old- road- unis</td>\n",
              "      <td>[Synset('strait.n.01'), Synset('like.n.02'), S...</td>\n",
              "      <td>['strait.n.01', 'like.n.02', 'old.s.07', 'road...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128395</th>\n",
              "      <td>11313</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Pretty- dull</td>\n",
              "      <td>[Synset('reasonably.r.01'), Synset('pall.v.01')]</td>\n",
              "      <td>['reasonably.r.01', 'pall.v.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128396</th>\n",
              "      <td>11313</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Buttons- pullovers</td>\n",
              "      <td>[Synset('release.n.08'), Synset('pullover.n.01')]</td>\n",
              "      <td>['release.n.08', 'pullover.n.01']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128397</th>\n",
              "      <td>11313</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Ill- check- uniform- book- see- theyve- always...</td>\n",
              "      <td>[Synset('ill.r.01'), Synset('check_mark.n.01')...</td>\n",
              "      <td>['ill.r.01', 'check_mark.n.01', 'uniform.n.01'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128398</th>\n",
              "      <td>11313</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128399</th>\n",
              "      <td>11313</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Ive- got- Astros- pullover- shirt- Astros- str...</td>\n",
              "      <td>[Synset('receive.v.02'), Synset('pullover.n.01...</td>\n",
              "      <td>['receive.v.02', 'pullover.n.01', 'shirt.v.01'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128400</th>\n",
              "      <td>11313</td>\n",
              "      <td>15.0</td>\n",
              "      <td>see- might- want- change</td>\n",
              "      <td>[Synset('visit.v.01'), Synset('might.n.01'), S...</td>\n",
              "      <td>['visit.v.01', 'might.n.01', 'wish.n.01', 'var...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128401</th>\n",
              "      <td>11313</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128402</th>\n",
              "      <td>11313</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128403 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index_P  index_sent                                          full_word  \\\n",
              "0            0         0.0           Well- im- sure- story- nad- seem- biased   \n",
              "1            0         1.0  disagree- statement- U- Media- ruin- Israels- ...   \n",
              "2            0         2.0                                         rediculous   \n",
              "3            0         3.0               U- media- pro- israeli- media- world   \n",
              "4            0         4.0  lived- Europe- realize- incidences- one- descr...   \n",
              "5            0         5.0                                                NaN   \n",
              "6            0         6.0  U- subsidizing- Israels- existance- Europeans-...   \n",
              "7            0         7.0  think- might- reason- report- clearly- atrocities   \n",
              "8            0         8.0                                                NaN   \n",
              "9            0         9.0            look- Jews- treating- races- got- power   \n",
              "10           0        10.0                                        unfortunate   \n",
              "11           1         0.0               Yeah- expect- people- read- FAQ- etc   \n",
              "12           1         1.0                    actually- accept- hard- atheism   \n",
              "13           1         2.0                   need- little- leap- faith- Jimmy   \n",
              "14           1         3.0                                 logic- runs- steam   \n",
              "15           1         4.0                        Jim- Sorry- cant- pity- Jim   \n",
              "16           1         5.0                                                NaN   \n",
              "17           1         6.0      Oh- well- pretend- end- happily- ever- anyway   \n",
              "18           1         7.0                                                NaN   \n",
              "19           1         8.0                                 Bye- Bye- Big- Jim   \n",
              "20           1         9.0                     forget- Flintstones- Chewables   \n",
              "21           1        10.0                                 Bake- Timmons- III   \n",
              "22           2         0.0  Although- realize- principle- one- strongest- ...   \n",
              "23           2         1.0  want- continue- think- tank- charade- fixation...   \n",
              "24           2         2.0                                                NaN   \n",
              "25           2         3.0                                                NaN   \n",
              "26           2         4.0  Everyone- group- recognizes- stupid- Center- P...   \n",
              "27           3         0.0                                                NaN   \n",
              "28           3         1.0  ATTs- last- product- area- priced- suspect- cl...   \n",
              "29           3         2.0  Thus- aside- attempting- legitimize- solidify-...   \n",
              "...        ...         ...                                                ...   \n",
              "128373   11309         2.0                                   Berkeley- campus   \n",
              "128374   11309         3.0  talk- sponsored- Berkeley- Israel- Action- Com...   \n",
              "128375   11311         0.0                                              agree   \n",
              "128376   11311         1.0             Home- runs- Clemens- always- memorable   \n",
              "128377   11311         2.0                  Kinda- like- eclipses- hurricanes   \n",
              "128378   11311         3.0                                                NaN   \n",
              "128379   11312         0.0  used- HP- DeskJet- Orange- Micros- Grappler- L...   \n",
              "128380   11312         1.0  update- system- System7- Kanji- Talk- print- D...   \n",
              "128381   11312         2.0                                                NaN   \n",
              "128382   11312         3.0                              use- DeskJet- System7   \n",
              "128383   11312         4.0                Please- tell- use- DeskJet- System7   \n",
              "128384   11312         5.0                                                NaN   \n",
              "128385   11313         0.0                                   argument- Murphy   \n",
              "128386   11313         1.0                                                NaN   \n",
              "128387   11313         2.0                                                NaN   \n",
              "128388   11313         3.0  seemed- viable- setup- guy- guess- thats- cons...   \n",
              "128389   11313         4.0                                                NaN   \n",
              "128390   11313         5.0                                      Im- concerned   \n",
              "128391   11313         6.0                                                NaN   \n",
              "128392   11313         7.0                                 expect- come- fine   \n",
              "128393   11313         8.0                                                NaN   \n",
              "128394   11313         9.0                      sounds- like- old- road- unis   \n",
              "128395   11313        10.0                                       Pretty- dull   \n",
              "128396   11313        11.0                                 Buttons- pullovers   \n",
              "128397   11313        12.0  Ill- check- uniform- book- see- theyve- always...   \n",
              "128398   11313        13.0                                                NaN   \n",
              "128399   11313        14.0  Ive- got- Astros- pullover- shirt- Astros- str...   \n",
              "128400   11313        15.0                           see- might- want- change   \n",
              "128401   11313        16.0                                                NaN   \n",
              "128402   11313        17.0                                                NaN   \n",
              "\n",
              "                                                    lesks  \\\n",
              "0       [Synset('well.v.01'), Synset('surely.r.01'), S...   \n",
              "1       [Synset('disagree.v.02'), Synset('statement.n....   \n",
              "2                                                      []   \n",
              "3       [Synset('uranium.n.01'), Synset('medium.n.08')...   \n",
              "4       [Synset('live.v.07'), Synset('europe.n.01'), S...   \n",
              "5                                                      []   \n",
              "6       [Synset('uranium.n.01'), Synset('subsidize.v.0...   \n",
              "7       [Synset('think.v.13'), Synset('might.n.01'), S...   \n",
              "8                                                      []   \n",
              "9       [Synset('spirit.n.02'), Synset('jew.n.01'), Sy...   \n",
              "10                           [Synset('unfortunate.n.01')]   \n",
              "11      [Synset('yea.r.01'), Synset('expect.v.05'), Sy...   \n",
              "12      [Synset('actually.r.04'), Synset('accept.v.11'...   \n",
              "13      [Synset('need.v.03'), Synset('little.s.08'), S...   \n",
              "14      [Synset('logic.n.05'), Synset('tend.v.01'), Sy...   \n",
              "15      [Synset('regretful.a.01'), Synset('slang.n.02'...   \n",
              "16                                                     []   \n",
              "17      [Synset('ohio.n.01'), Synset('well.v.01'), Syn...   \n",
              "18                                                     []   \n",
              "19      [Synset('bye.n.01'), Synset('bye.n.01'), Synse...   \n",
              "20      [Synset('forget.v.04'), Synset('flintstone.n.0...   \n",
              "21           [Synset('broil.v.02'), Synset('three.s.01')]   \n",
              "22      [Synset('realize.v.06'), Synset('principle.n.0...   \n",
              "23      [Synset('wish.n.01'), Synset('stay.v.04'), Syn...   \n",
              "24                                                     []   \n",
              "25                                                     []   \n",
              "26      [Synset('group.v.02'), Synset('recognize.v.08'...   \n",
              "27                                                     []   \n",
              "28      [Synset('last.v.01'), Synset('product.n.05'), ...   \n",
              "29      [Synset('thus.r.02'), Synset('digression.n.01'...   \n",
              "...                                                   ...   \n",
              "128373   [Synset('berkeley.n.02'), Synset('campus.n.01')]   \n",
              "128374  [Synset('talk.n.03'), Synset('patronize.v.02')...   \n",
              "128375                             [Synset('agree.v.02')]   \n",
              "128376  [Synset('home_plate.n.01'), Synset('tend.v.01'...   \n",
              "128377  [Synset('rather.r.02'), Synset('like.n.02'), S...   \n",
              "128378                                                 []   \n",
              "128379  [Synset('use.v.01'), Synset('horsepower.n.01')...   \n",
              "128380  [Synset('update.v.03'), Synset('system.n.08'),...   \n",
              "128381                                                 []   \n",
              "128382                               [Synset('use.v.01')]   \n",
              "128383  [Synset('please.v.03'), Synset('tell.v.03'), S...   \n",
              "128384                                                 []   \n",
              "128385  [Synset('controversy.n.01'), Synset('potato.n....   \n",
              "128386                                                 []   \n",
              "128387                                                 []   \n",
              "128388  [Synset('look.v.02'), Synset('viable.s.02'), S...   \n",
              "128389                                                 []   \n",
              "128390                         [Synset('concerned.s.02')]   \n",
              "128391                                                 []   \n",
              "128392  [Synset('have_a_bun_in_the_oven.v.01'), Synset...   \n",
              "128393                                                 []   \n",
              "128394  [Synset('strait.n.01'), Synset('like.n.02'), S...   \n",
              "128395   [Synset('reasonably.r.01'), Synset('pall.v.01')]   \n",
              "128396  [Synset('release.n.08'), Synset('pullover.n.01')]   \n",
              "128397  [Synset('ill.r.01'), Synset('check_mark.n.01')...   \n",
              "128398                                                 []   \n",
              "128399  [Synset('receive.v.02'), Synset('pullover.n.01...   \n",
              "128400  [Synset('visit.v.01'), Synset('might.n.01'), S...   \n",
              "128401                                                 []   \n",
              "128402                                                 []   \n",
              "\n",
              "                                               lesks_name  \n",
              "0       ['well.v.01', 'surely.r.01', 'story.n.02', 'ni...  \n",
              "1       ['disagree.v.02', 'statement.n.07', 'uranium.n...  \n",
              "2                                                      []  \n",
              "3       ['uranium.n.01', 'medium.n.08', 'pro.r.01', 'i...  \n",
              "4       ['live.v.07', 'europe.n.01', 'realize.v.06', '...  \n",
              "5                                                      []  \n",
              "6       ['uranium.n.01', 'subsidize.v.02', 'israel.n.0...  \n",
              "7       ['think.v.13', 'might.n.01', 'reason.v.01', 'r...  \n",
              "8                                                      []  \n",
              "9       ['spirit.n.02', 'jew.n.01', 'treat.v.08', 'sub...  \n",
              "10                                   ['unfortunate.n.01']  \n",
              "11      ['yea.r.01', 'expect.v.05', 'people.n.03', 'un...  \n",
              "12      ['actually.r.04', 'accept.v.11', 'hard.s.10', ...  \n",
              "13      ['need.v.03', 'little.s.08', 'leap.n.01', 'rel...  \n",
              "14            ['logic.n.05', 'tend.v.01', 'steamer.v.01']  \n",
              "15      ['regretful.a.01', 'slang.n.02', 'commiseratio...  \n",
              "16                                                     []  \n",
              "17      ['ohio.n.01', 'well.v.01', 'pretend.v.03', 'go...  \n",
              "18                                                     []  \n",
              "19                 ['bye.n.01', 'bye.n.01', 'large.a.01']  \n",
              "20                     ['forget.v.04', 'flintstone.n.01']  \n",
              "21                           ['broil.v.02', 'three.s.01']  \n",
              "22      ['realize.v.06', 'principle.n.04', 'one.s.06',...  \n",
              "23      ['wish.n.01', 'stay.v.04', 'think.v.13', 'tank...  \n",
              "24                                                     []  \n",
              "25                                                     []  \n",
              "26      ['group.v.02', 'recognize.v.08', 'stupid.n.01'...  \n",
              "27                                                     []  \n",
              "28      ['last.v.01', 'product.n.05', 'sphere.n.01', '...  \n",
              "29      ['thus.r.02', 'digression.n.01', 'undertake.v....  \n",
              "...                                                   ...  \n",
              "128373                   ['berkeley.n.02', 'campus.n.01']  \n",
              "128374  ['talk.n.03', 'patronize.v.02', 'berkeley.n.02...  \n",
              "128375                                     ['agree.v.02']  \n",
              "128376  ['home_plate.n.01', 'tend.v.01', 'clemens.n.01...  \n",
              "128377  ['rather.r.02', 'like.n.02', 'overshadow.v.01'...  \n",
              "128378                                                 []  \n",
              "128379  ['use.v.01', 'horsepower.n.01', 'orange.s.01',...  \n",
              "128380  ['update.v.03', 'system.n.08', 'talk.n.03', 'p...  \n",
              "128381                                                 []  \n",
              "128382                                       ['use.v.01']  \n",
              "128383           ['please.v.03', 'tell.v.03', 'use.v.01']  \n",
              "128384                                                 []  \n",
              "128385                ['controversy.n.01', 'potato.n.01']  \n",
              "128386                                                 []  \n",
              "128387                                                 []  \n",
              "128388  ['look.v.02', 'viable.s.02', 'frame-up.n.01', ...  \n",
              "128389                                                 []  \n",
              "128390                                 ['concerned.s.02']  \n",
              "128391                                                 []  \n",
              "128392  ['have_a_bun_in_the_oven.v.01', 'total.v.01', ...  \n",
              "128393                                                 []  \n",
              "128394  ['strait.n.01', 'like.n.02', 'old.s.07', 'road...  \n",
              "128395                   ['reasonably.r.01', 'pall.v.01']  \n",
              "128396                  ['release.n.08', 'pullover.n.01']  \n",
              "128397  ['ill.r.01', 'check_mark.n.01', 'uniform.n.01'...  \n",
              "128398                                                 []  \n",
              "128399  ['receive.v.02', 'pullover.n.01', 'shirt.v.01'...  \n",
              "128400  ['visit.v.01', 'might.n.01', 'wish.n.01', 'var...  \n",
              "128401                                                 []  \n",
              "128402                                                 []  \n",
              "\n",
              "[128403 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "metadata": {
        "id": "r-viOg2QGplO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p=read_cvs_by_pands(path_database,'pragraph_index_20.csv',None,0)\n",
        "index_p_p=p['index']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNiJw3RnG2tA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "5bdde13c-40a7-4ac8-91b2-35d863a5e3f2"
      },
      "cell_type": "code",
      "source": [
        "l_names=[]\n",
        "for i in range(len(index_p_p)) :\n",
        "    l_names=l[l['index_P']==str(i)]['lesks_name']\n",
        "print(l_names)"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128385                  ['controversy.n.01', 'potato.n.01']\n",
            "128386                                                   []\n",
            "128387                                                   []\n",
            "128388    ['look.v.02', 'viable.s.02', 'frame-up.n.01', ...\n",
            "128389                                                   []\n",
            "128390                                   ['concerned.s.02']\n",
            "128391                                                   []\n",
            "128392    ['have_a_bun_in_the_oven.v.01', 'total.v.01', ...\n",
            "128393                                                   []\n",
            "128394    ['strait.n.01', 'like.n.02', 'old.s.07', 'road...\n",
            "128395                     ['reasonably.r.01', 'pall.v.01']\n",
            "128396                    ['release.n.08', 'pullover.n.01']\n",
            "128397    ['ill.r.01', 'check_mark.n.01', 'uniform.n.01'...\n",
            "128398                                                   []\n",
            "128399    ['receive.v.02', 'pullover.n.01', 'shirt.v.01'...\n",
            "128400    ['visit.v.01', 'might.n.01', 'wish.n.01', 'var...\n",
            "128401                                                   []\n",
            "128402                                                   []\n",
            "Name: lesks_name, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iCxyYidh13d-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "effd1da2-0e75-4d28-d820-ff7369edd4c1"
      },
      "cell_type": "code",
      "source": [
        "len(index_p_p)\n",
        "l_names=l[l['index_P']==str(11313)]['lesks_name']\n",
        "l_names"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128385                  ['controversy.n.01', 'potato.n.01']\n",
              "128386                                                   []\n",
              "128387                                                   []\n",
              "128388    ['look.v.02', 'viable.s.02', 'frame-up.n.01', ...\n",
              "128389                                                   []\n",
              "128390                                   ['concerned.s.02']\n",
              "128391                                                   []\n",
              "128392    ['have_a_bun_in_the_oven.v.01', 'total.v.01', ...\n",
              "128393                                                   []\n",
              "128394    ['strait.n.01', 'like.n.02', 'old.s.07', 'road...\n",
              "128395                     ['reasonably.r.01', 'pall.v.01']\n",
              "128396                    ['release.n.08', 'pullover.n.01']\n",
              "128397    ['ill.r.01', 'check_mark.n.01', 'uniform.n.01'...\n",
              "128398                                                   []\n",
              "128399    ['receive.v.02', 'pullover.n.01', 'shirt.v.01'...\n",
              "128400    ['visit.v.01', 'might.n.01', 'wish.n.01', 'var...\n",
              "128401                                                   []\n",
              "128402                                                   []\n",
              "Name: lesks_name, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 321
        }
      ]
    },
    {
      "metadata": {
        "id": "M_WXdPGcRbc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5eefc7fc-a402-48cb-af8b-0e3481f6fd6d"
      },
      "cell_type": "code",
      "source": [
        "def isNotBlank (myString):\n",
        "    if myString and myString.strip():\n",
        "        #myString is not None AND myString is not empty or blank\n",
        "        return True\n",
        "    #myString is None OR myString is empty or blank\n",
        "    return False\n",
        "isNotBlank(' ')"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 340
        }
      ]
    },
    {
      "metadata": {
        "id": "gUeT72KCmmLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def paragarph_to_lesk():\n",
        "    pragraph_list=[]\n",
        "    for p in range(len(index_p_p)) :\n",
        "        #print(p)\n",
        "        l_names=l[l['index_P']==str(p)]['lesks_name']\n",
        "        #print(len(l_names))\n",
        "\n",
        "        l_name_one_paragraph=''\n",
        "        paragraph_row=[]\n",
        "        for i in range(len(l_names)):\n",
        "            l_name_one_paragraph+=l_names.get_values()[i].replace('[','').replace(']',',').strip()\n",
        "\n",
        "        if isNotBlank(l_name_one_paragraph.replace(',','')):\n",
        "\n",
        "\n",
        "            paragraph_row.append(p)\n",
        "            paragraph_row.append(l_name_one_paragraph)\n",
        "            pragraph_list.append(paragraph_row)\n",
        "        else:\n",
        "            print(p,\"pppppppppppppp\")\n",
        "    #print(pragraph_list)\n",
        "    header_list=['index_P','lesk_list']\n",
        "    df = pd.DataFrame(pragraph_list,columns=header_list)\n",
        "    df.to_csv(path_database+'paragraph_lesk_20.csv', encoding='utf-8', index=False)  \n",
        "    return df\n",
        "    #df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQr4yylSohoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "314ee587-7e26-41f2-80bd-aa2802c91b9e"
      },
      "cell_type": "code",
      "source": [
        "p_lesk=read_cvs_by_pands(path_database,'paragraph_lesk_20.csv',None,0)\n",
        "#p_lesk[p_lesk['lesk_list']=='[]']\n",
        "p_lesk['lesk_list'].applay(replace(\"'\",''))"
      ],
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-365-96c70c62a299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp_lesk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_cvs_by_pands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_database\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'paragraph_lesk_20.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#p_lesk[p_lesk['lesk_list']=='[]']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp_lesk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lesk_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'applay'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "joKLoGX-rgd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6e7ea7ff-f4cc-4a49-c1cf-e7c63a963cba"
      },
      "cell_type": "code",
      "source": [
        "document_0 = \"China has a strong economy that is growing at a rapid pace. However politically it differs greatly from the US Economy.\"\n",
        "document_1 = \"At last, China seems serious about confronting an endemic problem: domestic violence and corruption.\"\n",
        "document_2 = \"Japan's prime minister, Shinzo Abe, is working towards healing the economic turmoil in his own country for his view on the future of his people.\"\n",
        "document_3 = \"Vladimir Putin is working hard to fix the economy in Russia as the Ruble has tumbled.\"\n",
        "document_4 = \"What's the future of Abenomics? We asked Shinzo Abe for his views\"\n",
        "document_5 = \"Obama has eased sanctions on Cuba while accelerating those against the Russian Economy, even as the Ruble's value falls almost daily.\"\n",
        "document_6 = \"Vladimir Putin is riding a horse while hunting deer. Vladimir Putin always seems so serious about things - even riding horses. Is he crazy?\"\n",
        "\n",
        "all_documents = [document_0, document_1, document_2, document_3, document_4, document_5, document_6]\n",
        "all_documents\n",
        "#in Scikit-Learn\n",
        "tokenize = lambda doc: doc.lower().split(\" \")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)\n",
        "sklearn_representation = sklearn_tfidf.fit_transform(all_documents)\n",
        "sklearn_representation.data\n",
        "sklearn_tfidf.get_feature_names"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method CountVectorizer.get_feature_names of TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=0,\n",
              "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=False,\n",
              "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
              "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=<function <lambda> at 0x7f4e6dc3e620>, use_idf=True,\n",
              "        vocabulary=None)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 388
        }
      ]
    },
    {
      "metadata": {
        "id": "Cq22vLjIxEh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "9d5ce2e4-063d-4428-cc8c-580c79f107bf"
      },
      "cell_type": "code",
      "source": [
        "print(p_lesk['lesk_list'][1:10])"
      ],
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    'yea.r.01', 'expect.v.05', 'people.n.03', 'und...\n",
            "2    'realize.v.06', 'principle.n.04', 'one.s.06', ...\n",
            "3    ,'last.v.01', 'product.n.05', 'sphere.n.01', '...\n",
            "4    'well.v.01', 'variety.n.06', 'score.v.06', 'pl...\n",
            "5    ,'look.v.02', 'sidereal_day.n.01', 'stay.v.09'...\n",
            "6    'very_well.r.02','record.v.01', 'show.v.12', '...\n",
            "7    'voice.v.02', 'wish.v.02', 'desirous.a.01', 't...\n",
            "8    'cipher.n.04', 'suppose.v.01', 'let.v.01', 'us...\n",
            "9    'wonder.v.01', 'shed.n.01', 'sparkle.n.01', 'e...\n",
            "Name: lesk_list, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wxbm9fgrtjLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cv_tfidf_lesk = TfidfVectorizer(analyzer='word',token_pattern=\"'\"+'(?u)\\\\b\\\\w\\\\w+\\\\b\\\\.\\\\w\\\\.\\\\d\\\\d'+\"'\") #lesk\n",
        "#print(type(texts_lesk))\n",
        "cv_tfidf_fit_lesk=cv_tfidf_lesk.fit_transform(p_lesk['lesk_list']).toarray()\n",
        "df_tfidf_lesk=pd.DataFrame(cv_tfidf_fit_lesk,columns=cv_tfidf_lesk.get_feature_names(),index=p_lesk['index_P'])\n",
        "df_tfidf_lesk.to_csv(path_database+'tf_idf_lesk_table_20.csv')\n",
        "#save_file_to_database(texts_lesk,path_database,lesk_paragraph,lesk_paragraph_list)\n",
        "df_tfidf_lesk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FGXU4MQMHF2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
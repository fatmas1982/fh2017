{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_path = '/home/cloudera/cs2.txt'\n",
    "def read_file(str):\n",
    "    file = open(str,'r')\n",
    "    txt=file.read()\n",
    "    #print(txt)\n",
    "    return txt\n",
    "txt=read_file(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Paragraphs 7\n"
     ]
    }
   ],
   "source": [
    "def txt_pragraphs(str):\n",
    "    pragraphs = str.split(\"\\n\\n\")\n",
    "    return pragraphs\n",
    "pragraphs=txt_pragraphs(txt)\n",
    "type(pragraphs)\n",
    "print (\"Number of Paragraphs\",len(pragraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "doc_set=[]\n",
    "for index in range(len(pragraphs)):\n",
    "    doc_set.append(pragraphs[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 491\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 0.016s.\n",
      "(7, 196)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#http://programtalk.com/python-examples/sklearn.decomposition.NMF/\n",
    "\n",
    "\n",
    "\n",
    "#https://de.dariah.eu/tatom/topic_model_python.html\n",
    "\n",
    "pragraphs_names=[]\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "new_stop_words = ['the', 'that', 'to', 'as', 'there', 'has', 'and', 'or', 'is', 'not', 'a', 'of', 'but', 'in', 'by', 'on', 'are', 'it', 'if','what','where','how','when']\n",
    "new_stop_words2=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now','even','until','then','must']\n",
    "english_stops = set(stopwords.words('english'))\n",
    "\n",
    "#NUM_TOPICS = 5\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "    \n",
    "\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "#print(len(doc_set))\n",
    "words_nums=0\n",
    "# loop through document list\n",
    "x=0\n",
    "all_words=[]\n",
    "idx_pragraph=0\n",
    "for i in doc_set:#pragraphs list\n",
    "    \n",
    "    pragraphs_names.append('Pragraph_no_'+str(idx_pragraph))\n",
    "    \n",
    "    idx_pragraph += 1\n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    #tokens = tokenizer.tokenize(raw)\n",
    "    sentences_pragraph=sent_tokenize(raw)\n",
    "    \n",
    "    # remove stop words from tokens\n",
    "    #stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    words_pragraph=''\n",
    "    for s in sentences_pragraph:\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        stopped_tokens = [s for s in tokens if not s in en_stop and not s in new_stop_words and not s in new_stop_words2 and not s in english_stops]\n",
    "        #print(\"stopped_tokens \\n\",stopped_tokens)\n",
    "        words_nums+=len(stopped_tokens)\n",
    "        #print(stopped_tokens)\n",
    "        #lesk_sentence=[]\n",
    "        wordsent=''\n",
    "        for word in stopped_tokens:\n",
    "            lesk_word=lesk_synset=lesk(s,word, 'n')\n",
    "            \n",
    "            if lesk_word is not None:\n",
    "                #print(lesk_word)\n",
    "                wordsent+=' '+str(lesk_word)\n",
    "                words_pragraph+=' '+\"'\"+lesk_word.name()+\"'\"\n",
    "                all_words.append(lesk_word.name())\n",
    "              \n",
    "    x=x+1\n",
    "    \n",
    "   \n",
    "    texts.append(words_pragraph)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b\\\\.\\\\w\\\\.\\\\d\\\\d')\n",
    "#print(tfidf_vectorizer)\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "#print(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "A = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "print(A.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation()\n",
    "topic_document = lda.fit_transform(A)# W\n",
    "topic_word_matrix = []\n",
    "document_topic_matrix = []\n",
    "vocabulary_size = len(all_words)\n",
    "#print(\"2\",len(all_words))\n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "data_rows=[]\n",
    "topic_name=[]\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "#print('fff',len(tfidf_feature_names))\n",
    "for topic_idx, topic in enumerate(lda.components_):#word topic H\n",
    "    \n",
    "    topic_row=[]\n",
    "    topic_arg_sort=topic.argsort()\n",
    "    for i in range(len(topic_arg_sort)):\n",
    "        row.append(topic_idx)\n",
    "        col.append(i)\n",
    "        data.append(topic[i])\n",
    "        topic_row.append(topic[i])\n",
    "    data_rows.append(topic_row)\n",
    "    topic_name.append('Topic_no_'+str(topic_idx))\n",
    "       \n",
    "row = []\n",
    "col = []\n",
    "data = []\n",
    "doc_count = 0\n",
    "data_rows_Doc=[]\n",
    "\n",
    "for doc in topic_document: # topic Document W\n",
    "    topic_count = 0\n",
    "    \n",
    "    topic_row=[]\n",
    "    doc_arg_sort=doc.argsort()\n",
    "    for topic_weight in doc_arg_sort:\n",
    "        row.append(doc_count)\n",
    "        col.append(topic_count)\n",
    "        data.append(topic_weight)\n",
    "        topic_row.append(topic_weight)\n",
    "    \n",
    "        \n",
    "        topic_count += 1\n",
    "    data_rows_Doc.append(topic_row)\n",
    "   \n",
    "    doc_count += 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ace.n.03</th>\n",
       "      <th>acquiring.n.01</th>\n",
       "      <th>algorithm.n.01</th>\n",
       "      <th>automaton.n.02</th>\n",
       "      <th>beginning.n.05</th>\n",
       "      <th>bind.n.01</th>\n",
       "      <th>broad.n.01</th>\n",
       "      <th>building.n.04</th>\n",
       "      <th>business.n.04</th>\n",
       "      <th>calculation.n.02</th>\n",
       "      <th>...</th>\n",
       "      <th>view.n.02</th>\n",
       "      <th>view.n.07</th>\n",
       "      <th>way.n.12</th>\n",
       "      <th>well.n.05</th>\n",
       "      <th>whitethorn.n.01</th>\n",
       "      <th>wish.n.01</th>\n",
       "      <th>workplace.n.01</th>\n",
       "      <th>world.n.02</th>\n",
       "      <th>world.n.08</th>\n",
       "      <th>young.n.04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic_no_0</th>\n",
       "      <td>0.279771</td>\n",
       "      <td>0.261438</td>\n",
       "      <td>0.268243</td>\n",
       "      <td>0.266782</td>\n",
       "      <td>0.284626</td>\n",
       "      <td>0.262361</td>\n",
       "      <td>0.259698</td>\n",
       "      <td>0.242841</td>\n",
       "      <td>0.279245</td>\n",
       "      <td>0.317041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246369</td>\n",
       "      <td>0.273972</td>\n",
       "      <td>0.343489</td>\n",
       "      <td>0.249193</td>\n",
       "      <td>0.282387</td>\n",
       "      <td>0.276594</td>\n",
       "      <td>0.271741</td>\n",
       "      <td>0.292751</td>\n",
       "      <td>0.274287</td>\n",
       "      <td>0.322127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_1</th>\n",
       "      <td>0.263069</td>\n",
       "      <td>0.283264</td>\n",
       "      <td>0.242272</td>\n",
       "      <td>0.287946</td>\n",
       "      <td>0.281378</td>\n",
       "      <td>0.275091</td>\n",
       "      <td>0.261156</td>\n",
       "      <td>0.299691</td>\n",
       "      <td>0.295299</td>\n",
       "      <td>0.282382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316235</td>\n",
       "      <td>0.279290</td>\n",
       "      <td>0.311538</td>\n",
       "      <td>0.274457</td>\n",
       "      <td>0.281880</td>\n",
       "      <td>0.296245</td>\n",
       "      <td>0.301199</td>\n",
       "      <td>0.285569</td>\n",
       "      <td>0.273488</td>\n",
       "      <td>0.287331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_2</th>\n",
       "      <td>0.289356</td>\n",
       "      <td>0.279622</td>\n",
       "      <td>0.325175</td>\n",
       "      <td>0.314120</td>\n",
       "      <td>0.240412</td>\n",
       "      <td>0.233301</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.274401</td>\n",
       "      <td>0.291366</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297179</td>\n",
       "      <td>0.311650</td>\n",
       "      <td>0.289742</td>\n",
       "      <td>0.225533</td>\n",
       "      <td>0.279077</td>\n",
       "      <td>0.279737</td>\n",
       "      <td>0.273444</td>\n",
       "      <td>0.260227</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>0.266357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_3</th>\n",
       "      <td>0.271365</td>\n",
       "      <td>0.273450</td>\n",
       "      <td>0.247951</td>\n",
       "      <td>0.237710</td>\n",
       "      <td>0.288142</td>\n",
       "      <td>0.281682</td>\n",
       "      <td>0.275569</td>\n",
       "      <td>0.286034</td>\n",
       "      <td>0.251931</td>\n",
       "      <td>0.276816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284023</td>\n",
       "      <td>0.268187</td>\n",
       "      <td>0.271029</td>\n",
       "      <td>0.246156</td>\n",
       "      <td>0.280920</td>\n",
       "      <td>0.299968</td>\n",
       "      <td>0.269344</td>\n",
       "      <td>0.304757</td>\n",
       "      <td>0.296165</td>\n",
       "      <td>0.306062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_4</th>\n",
       "      <td>0.251794</td>\n",
       "      <td>0.291410</td>\n",
       "      <td>0.276379</td>\n",
       "      <td>0.268338</td>\n",
       "      <td>0.255870</td>\n",
       "      <td>0.274312</td>\n",
       "      <td>0.305307</td>\n",
       "      <td>0.278598</td>\n",
       "      <td>0.290967</td>\n",
       "      <td>0.283627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278926</td>\n",
       "      <td>0.299983</td>\n",
       "      <td>0.286213</td>\n",
       "      <td>0.257923</td>\n",
       "      <td>0.284548</td>\n",
       "      <td>0.304759</td>\n",
       "      <td>0.288429</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.268630</td>\n",
       "      <td>0.300627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_5</th>\n",
       "      <td>0.271233</td>\n",
       "      <td>0.274945</td>\n",
       "      <td>0.274621</td>\n",
       "      <td>0.312966</td>\n",
       "      <td>0.287367</td>\n",
       "      <td>0.303753</td>\n",
       "      <td>0.246130</td>\n",
       "      <td>0.274375</td>\n",
       "      <td>0.260125</td>\n",
       "      <td>0.298181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278841</td>\n",
       "      <td>0.276641</td>\n",
       "      <td>0.245812</td>\n",
       "      <td>0.282925</td>\n",
       "      <td>0.267977</td>\n",
       "      <td>0.273714</td>\n",
       "      <td>0.271783</td>\n",
       "      <td>0.291046</td>\n",
       "      <td>0.272208</td>\n",
       "      <td>0.294661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_6</th>\n",
       "      <td>0.309222</td>\n",
       "      <td>0.290602</td>\n",
       "      <td>0.290716</td>\n",
       "      <td>0.282799</td>\n",
       "      <td>0.289893</td>\n",
       "      <td>0.263696</td>\n",
       "      <td>0.283041</td>\n",
       "      <td>0.264532</td>\n",
       "      <td>0.265550</td>\n",
       "      <td>0.275010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268119</td>\n",
       "      <td>0.246763</td>\n",
       "      <td>0.258332</td>\n",
       "      <td>0.261602</td>\n",
       "      <td>0.264152</td>\n",
       "      <td>0.290038</td>\n",
       "      <td>0.257141</td>\n",
       "      <td>0.284691</td>\n",
       "      <td>0.275550</td>\n",
       "      <td>0.291668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_7</th>\n",
       "      <td>0.270946</td>\n",
       "      <td>0.279471</td>\n",
       "      <td>0.253102</td>\n",
       "      <td>0.427337</td>\n",
       "      <td>0.271800</td>\n",
       "      <td>0.278628</td>\n",
       "      <td>0.253815</td>\n",
       "      <td>0.278512</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.296176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>0.244323</td>\n",
       "      <td>0.281988</td>\n",
       "      <td>0.280971</td>\n",
       "      <td>0.420113</td>\n",
       "      <td>0.275856</td>\n",
       "      <td>0.291532</td>\n",
       "      <td>0.308622</td>\n",
       "      <td>0.520207</td>\n",
       "      <td>0.277962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_8</th>\n",
       "      <td>0.296507</td>\n",
       "      <td>0.280289</td>\n",
       "      <td>0.415635</td>\n",
       "      <td>0.296550</td>\n",
       "      <td>0.359123</td>\n",
       "      <td>0.359916</td>\n",
       "      <td>0.297290</td>\n",
       "      <td>0.272497</td>\n",
       "      <td>0.279626</td>\n",
       "      <td>0.258311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373542</td>\n",
       "      <td>0.374944</td>\n",
       "      <td>0.380974</td>\n",
       "      <td>0.324265</td>\n",
       "      <td>0.273115</td>\n",
       "      <td>0.269427</td>\n",
       "      <td>0.234148</td>\n",
       "      <td>0.281273</td>\n",
       "      <td>0.338056</td>\n",
       "      <td>0.370109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic_no_9</th>\n",
       "      <td>0.347986</td>\n",
       "      <td>0.347990</td>\n",
       "      <td>0.398334</td>\n",
       "      <td>0.283391</td>\n",
       "      <td>0.239365</td>\n",
       "      <td>0.269412</td>\n",
       "      <td>0.342622</td>\n",
       "      <td>0.364686</td>\n",
       "      <td>0.338980</td>\n",
       "      <td>0.556378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275698</td>\n",
       "      <td>0.274811</td>\n",
       "      <td>0.272591</td>\n",
       "      <td>0.410171</td>\n",
       "      <td>0.327857</td>\n",
       "      <td>0.332553</td>\n",
       "      <td>0.423461</td>\n",
       "      <td>0.307509</td>\n",
       "      <td>0.282432</td>\n",
       "      <td>0.238505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ace.n.03  acquiring.n.01  algorithm.n.01  automaton.n.02  \\\n",
       "Topic_no_0  0.279771        0.261438        0.268243        0.266782   \n",
       "Topic_no_1  0.263069        0.283264        0.242272        0.287946   \n",
       "Topic_no_2  0.289356        0.279622        0.325175        0.314120   \n",
       "Topic_no_3  0.271365        0.273450        0.247951        0.237710   \n",
       "Topic_no_4  0.251794        0.291410        0.276379        0.268338   \n",
       "Topic_no_5  0.271233        0.274945        0.274621        0.312966   \n",
       "Topic_no_6  0.309222        0.290602        0.290716        0.282799   \n",
       "Topic_no_7  0.270946        0.279471        0.253102        0.427337   \n",
       "Topic_no_8  0.296507        0.280289        0.415635        0.296550   \n",
       "Topic_no_9  0.347986        0.347990        0.398334        0.283391   \n",
       "\n",
       "            beginning.n.05  bind.n.01  broad.n.01  building.n.04  \\\n",
       "Topic_no_0        0.284626   0.262361    0.259698       0.242841   \n",
       "Topic_no_1        0.281378   0.275091    0.261156       0.299691   \n",
       "Topic_no_2        0.240412   0.233301    0.253496       0.274401   \n",
       "Topic_no_3        0.288142   0.281682    0.275569       0.286034   \n",
       "Topic_no_4        0.255870   0.274312    0.305307       0.278598   \n",
       "Topic_no_5        0.287367   0.303753    0.246130       0.274375   \n",
       "Topic_no_6        0.289893   0.263696    0.283041       0.264532   \n",
       "Topic_no_7        0.271800   0.278628    0.253815       0.278512   \n",
       "Topic_no_8        0.359123   0.359916    0.297290       0.272497   \n",
       "Topic_no_9        0.239365   0.269412    0.342622       0.364686   \n",
       "\n",
       "            business.n.04  calculation.n.02     ...      view.n.02  view.n.07  \\\n",
       "Topic_no_0       0.279245          0.317041     ...       0.246369   0.273972   \n",
       "Topic_no_1       0.295299          0.282382     ...       0.316235   0.279290   \n",
       "Topic_no_2       0.291366          0.274019     ...       0.297179   0.311650   \n",
       "Topic_no_3       0.251931          0.276816     ...       0.284023   0.268187   \n",
       "Topic_no_4       0.290967          0.283627     ...       0.278926   0.299983   \n",
       "Topic_no_5       0.260125          0.298181     ...       0.278841   0.276641   \n",
       "Topic_no_6       0.265550          0.275010     ...       0.268119   0.246763   \n",
       "Topic_no_7       0.296800          0.296176     ...       0.272099   0.244323   \n",
       "Topic_no_8       0.279626          0.258311     ...       0.373542   0.374944   \n",
       "Topic_no_9       0.338980          0.556378     ...       0.275698   0.274811   \n",
       "\n",
       "            way.n.12  well.n.05  whitethorn.n.01  wish.n.01  workplace.n.01  \\\n",
       "Topic_no_0  0.343489   0.249193         0.282387   0.276594        0.271741   \n",
       "Topic_no_1  0.311538   0.274457         0.281880   0.296245        0.301199   \n",
       "Topic_no_2  0.289742   0.225533         0.279077   0.279737        0.273444   \n",
       "Topic_no_3  0.271029   0.246156         0.280920   0.299968        0.269344   \n",
       "Topic_no_4  0.286213   0.257923         0.284548   0.304759        0.288429   \n",
       "Topic_no_5  0.245812   0.282925         0.267977   0.273714        0.271783   \n",
       "Topic_no_6  0.258332   0.261602         0.264152   0.290038        0.257141   \n",
       "Topic_no_7  0.281988   0.280971         0.420113   0.275856        0.291532   \n",
       "Topic_no_8  0.380974   0.324265         0.273115   0.269427        0.234148   \n",
       "Topic_no_9  0.272591   0.410171         0.327857   0.332553        0.423461   \n",
       "\n",
       "            world.n.02  world.n.08  young.n.04  \n",
       "Topic_no_0    0.292751    0.274287    0.322127  \n",
       "Topic_no_1    0.285569    0.273488    0.287331  \n",
       "Topic_no_2    0.260227    0.246533    0.266357  \n",
       "Topic_no_3    0.304757    0.296165    0.306062  \n",
       "Topic_no_4    0.289954    0.268630    0.300627  \n",
       "Topic_no_5    0.291046    0.272208    0.294661  \n",
       "Topic_no_6    0.284691    0.275550    0.291668  \n",
       "Topic_no_7    0.308622    0.520207    0.277962  \n",
       "Topic_no_8    0.281273    0.338056    0.370109  \n",
       "Topic_no_9    0.307509    0.282432    0.238505  \n",
       "\n",
       "[10 rows x 196 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word_topic=pd.DataFrame(data_rows,columns=tfidf_feature_names,index=topic_name)\n",
    "\n",
    "df_word_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_no_0</th>\n",
       "      <th>Topic_no_1</th>\n",
       "      <th>Topic_no_2</th>\n",
       "      <th>Topic_no_3</th>\n",
       "      <th>Topic_no_4</th>\n",
       "      <th>Topic_no_5</th>\n",
       "      <th>Topic_no_6</th>\n",
       "      <th>Topic_no_7</th>\n",
       "      <th>Topic_no_8</th>\n",
       "      <th>Topic_no_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_0</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_5</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pragraph_no_6</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic_no_0  Topic_no_1  Topic_no_2  Topic_no_3  Topic_no_4  \\\n",
       "Pragraph_no_0           3           6           5           4           1   \n",
       "Pragraph_no_1           3           0           1           5           6   \n",
       "Pragraph_no_2           3           0           1           6           5   \n",
       "Pragraph_no_3           6           3           0           5           1   \n",
       "Pragraph_no_4           0           6           3           1           5   \n",
       "Pragraph_no_5           3           6           0           5           1   \n",
       "Pragraph_no_6           6           5           3           1           0   \n",
       "\n",
       "               Topic_no_5  Topic_no_6  Topic_no_7  Topic_no_8  Topic_no_9  \n",
       "Pragraph_no_0           0           7           2           8           9  \n",
       "Pragraph_no_1           4           7           2           9           8  \n",
       "Pragraph_no_2           4           2           7           8           9  \n",
       "Pragraph_no_3           4           7           8           9           2  \n",
       "Pragraph_no_4           2           7           8           9           4  \n",
       "Pragraph_no_5           2           4           8           9           7  \n",
       "Pragraph_no_6           4           2           9           7           8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic=pd.DataFrame(data_rows_Doc,columns=topic_name,index=pragraphs_names)\n",
    "\n",
    "df_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
